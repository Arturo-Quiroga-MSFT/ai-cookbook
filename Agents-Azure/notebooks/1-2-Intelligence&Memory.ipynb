{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c958b3c8",
   "metadata": {},
   "source": [
    "**Original Code by Dave Ebbelaar** - Extended for Azure OpenAI by Arturo Quiroga\n",
    "\n",
    "# Azure OpenAI Agent Building Blocks\n",
    "\n",
    "This notebook demonstrates the fundamental building blocks for creating intelligent agents using Azure OpenAI. Each section covers a core component that enables sophisticated AI agent behavior:\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. An Azure OpenAI resource deployed\n",
    "2. Environment variables configured (see `.env.example`)\n",
    "3. Required Python packages installed: `openai`, `azure-identity`, `python-dotenv`\n",
    "\n",
    "## Building Blocks Overview\n",
    "\n",
    "The notebook is organized into key sections that demonstrate agent capabilities:\n",
    "- **Intelligence**: Core reasoning and response generation using Azure OpenAI\n",
    "- **Memory**: Conversation history management for context-aware interactions\n",
    "\n",
    "Each section includes both functional implementations and demonstration code to show the concepts in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0be625",
   "metadata": {},
   "source": [
    "## Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5f62f",
   "metadata": {},
   "source": [
    "\n",
    "Intelligence: The \"brain\" that processes information and makes decisions using Azure OpenAI LLMs.\n",
    "This component handles context understanding, instruction following, and response generation.\n",
    "\n",
    "Azure OpenAI Documentation: https://docs.microsoft.com/en-us/azure/cognitive-services/openai/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa620a",
   "metadata": {},
   "source": [
    "### Load required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ef03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3a26d",
   "metadata": {},
   "source": [
    "### Initialize Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f489aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_openai_client():\n",
    "    \"\"\"\n",
    "    Initialize Azure OpenAI client with proper authentication.\n",
    "    \n",
    "    Uses API key authentication for development and Managed Identity for production.\n",
    "    \"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    \n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    # Use API key if available (development), otherwise use Managed Identity (production)\n",
    "    if api_key:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    else:\n",
    "        # Use Managed Identity for production environments\n",
    "        credential = DefaultAzureCredential()\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=credential,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    \n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd0e77",
   "metadata": {},
   "source": [
    "### Azure OpenAI Client Configuration\n",
    "\n",
    "This function handles the authentication and initialization of the Azure OpenAI client. It supports two authentication methods:\n",
    "\n",
    "**Development Environment (API Key):**\n",
    "- Uses `AZURE_OPENAI_API_KEY` for simple authentication\n",
    "- Ideal for local development and testing\n",
    "\n",
    "**Production Environment (Managed Identity):**\n",
    "- Uses `DefaultAzureCredential` for secure, keyless authentication\n",
    "- Recommended for deployed applications in Azure\n",
    "- Automatically handles various Azure authentication scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b1166",
   "metadata": {},
   "source": [
    "### Basic Intelligence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee1f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Intelligence Output:\n",
      "**Artificial intelligence (AI)** is a branch of computer science focused on creating systems or programs that can perform tasks typically requiring human intelligence. These tasks include learning, reasoning, problem-solving, perception, understanding language, and even creativity.\n",
      "\n",
      "**In simple terms:**  \n",
      "AI refers to machines or software that can \"think\" or act in ways that mimic human capabilities.\n",
      "\n",
      "**Types of AI tasks include:**\n",
      "- Recognizing images or speech (e.g., facial recognition, voice assistants)\n",
      "- Understanding and generating human language (e.g., chatbots, translation)\n",
      "- Making decisions (e.g., recommendation systems, self-driving cars)\n",
      "- Learning from experience or data (e.g., machine learning algorithms)\n",
      "\n",
      "**Examples of AI in everyday life:**\n",
      "- Siri or Google Assistant answering questions\n",
      "- Netflix recommending shows\n",
      "- Spam filters in email\n",
      "- Self-driving cars interpreting their environment\n",
      "\n",
      "**Key point:**  \n",
      "Artificial intelligence is about making computers smart enough to do things that, until recently, only humans could do.\n"
     ]
    }
   ],
   "source": [
    "def basic_intelligence(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Basic intelligence function using Azure OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The input prompt for the AI model\n",
    "        \n",
    "    Returns:\n",
    "        Generated response text\n",
    "    \"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the basic intelligence function\n",
    "    result = basic_intelligence(prompt=\"What is artificial intelligence?\")\n",
    "    print(\"Basic Intelligence Output:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a66bb",
   "metadata": {},
   "source": [
    "### Intelligence Testing\n",
    "\n",
    "This section includes a test execution that demonstrates the basic intelligence function. When run, it will:\n",
    "1. Initialize the Azure OpenAI client\n",
    "2. Send a sample prompt about artificial intelligence\n",
    "3. Display the AI-generated response\n",
    "4. Show how the intelligence component processes and responds to queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496020d",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24866b",
   "metadata": {},
   "source": [
    "\n",
    "Memory: Stores and retrieves relevant information across interactions with Azure OpenAI.\n",
    "This component maintains conversation history and context to enable coherent multi-turn interactions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e55148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_openai_client():\n",
    "    \"\"\"\n",
    "    Initialize Azure OpenAI client with proper authentication.\n",
    "    \n",
    "    Uses API key authentication for development and Managed Identity for production.\n",
    "    \"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    \n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    # Use API key if available (development), otherwise use Managed Identity (production)\n",
    "    if api_key:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    else:\n",
    "        # Use Managed Identity for production environments\n",
    "        credential = DefaultAzureCredential()\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=credential,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    \n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6dc12",
   "metadata": {},
   "source": [
    "### Memory Demonstration Functions\n",
    "\n",
    "The following functions demonstrate the difference between maintaining conversation history (memory) and not maintaining it. This shows why memory is crucial for coherent multi-turn conversations with AI agents.\n",
    "\n",
    "### Memory Comparison Functions\n",
    "\n",
    "These functions demonstrate the difference between stateless and stateful interactions:\n",
    "- `ask_joke_without_memory()`: Makes isolated requests without context\n",
    "- `ask_followup_without_memory()`: Shows how AI loses context without memory\n",
    "- `ask_followup_with_memory()`: Demonstrates how conversation history enables context awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c294d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_joke_without_memory():\n",
    "    \"\"\"Ask for a joke without maintaining conversation history.\"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Tell me a joke about programming\"},\n",
    "            ],\n",
    "            temperature=0.8,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\"\n",
    "\n",
    "def ask_followup_without_memory():\n",
    "    \"\"\"Ask a follow-up question without conversation context.\"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"What was my previous question?\"},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\"\n",
    "\n",
    "\n",
    "def ask_followup_with_memory(joke_response: str):\n",
    "    \"\"\"Ask a follow-up question with conversation history maintained.\"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    # Maintain conversation history by including previous messages\n",
    "    conversation_history = [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke about programming\"},\n",
    "        {\"role\": \"assistant\", \"content\": joke_response},\n",
    "        {\"role\": \"user\", \"content\": \"What was my previous question?\"},\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=conversation_history,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24bc15",
   "metadata": {},
   "source": [
    "### ConversationMemory Class\n",
    "\n",
    "A production-ready memory management class that maintains conversation history across multiple interactions. This class provides methods to:\n",
    "- Add user and assistant messages to history\n",
    "- Generate responses while maintaining context\n",
    "- Clear conversation history when needed\n",
    "- Track message count for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8f13f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Memory Demo ===\n",
      "\n",
      "1. Asking for a joke...\n",
      "Response: Sure! Here's a programming joke for you:\n",
      "\n",
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs!\n",
      "\n",
      "2. Asking follow-up without memory...\n",
      "Response: I'm sorry, but I don't have access to your previous question. How can I assist you today?\n",
      "\n",
      "3. Asking follow-up with memory...\n",
      "Response: Your previous question was: \"Tell me a joke about programming.\"\n",
      "\n",
      "4. Using ConversationMemory class...\n",
      "Response 1: Certainly! Python is a high-level, interpreted programming language known for its simplicity and readability. It was created by Guido van Rossum and first released in 1991. Python emphasizes code readability with its use of significant indentation and a clean syntax, which makes it an excellent choice for beginners as well as experienced developers.\n",
      "\n",
      "### Key Features of Python:\n",
      "- **Easy to Learn and Use:** Python's syntax is clear and intuitive, making it accessible for newcomers.\n",
      "- **Interpreted Language:** Python code is executed line-by-line, which facilitates quick testing and debugging.\n",
      "- **Dynamically Typed:** You don’t need to declare variable types explicitly.\n",
      "- **Extensive Standard Library:** Python comes with a vast collection of modules and packages for various tasks like file I/O, system calls, web services, and more.\n",
      "- **Cross-Platform:** Python runs on Windows, macOS, Linux, and many other operating systems.\n",
      "- **Large Community and Ecosystem:** There are countless third-party libraries and frameworks for everything from web development (Django, Flask) to data science (Pandas, NumPy, TensorFlow).\n",
      "\n",
      "### Common Uses of Python:\n",
      "- **Web Development:** Frameworks like Django and Flask make building web applications straightforward.\n",
      "- **Data Science and Machine Learning:** Libraries such as NumPy, Pandas, Matplotlib, Scikit-learn, and TensorFlow support data analysis and AI.\n",
      "- **Automation and Scripting:** Python is often used to write scripts to automate repetitive tasks.\n",
      "- **Software Development:** Python can be used for backend development, prototyping, and testing.\n",
      "- **Education:** Its simplicity makes it a popular teaching language.\n",
      "\n",
      "### Example Python Code:\n",
      "```python\n",
      "def greet(name):\n",
      "    print(f\"Hello, {name}!\")\n",
      "\n",
      "greet(\"World\")\n",
      "```\n",
      "\n",
      "If you want to learn Python or have specific questions about it, feel free to ask!\n",
      "\n",
      "Response 2: Python has many advantages that have contributed to its widespread popularity. Here are some of its main advantages:\n",
      "\n",
      "1. **Easy to Learn and Use**  \n",
      "   Python’s simple and clean syntax makes it easy for beginners to pick up quickly and for experienced programmers to write clear, readable code.\n",
      "\n",
      "2. **Readability and Maintainability**  \n",
      "   Python’s use of indentation to define code blocks enforces readability, which makes maintaining and updating code easier.\n",
      "\n",
      "3. **Extensive Standard Library**  \n",
      "   Python comes with a rich standard library that supports many common programming tasks, such as file handling, regular expressions, networking, and web services, reducing the need to write code from scratch.\n",
      "\n",
      "4. **Large Ecosystem and Third-Party Libraries**  \n",
      "   There are thousands of third-party libraries and frameworks available for Python, covering areas like web development, scientific computing, machine learning, automation, and more.\n",
      "\n",
      "5. **Cross-Platform Compatibility**  \n",
      "   Python runs on multiple operating systems including Windows, macOS, Linux, and others, allowing developers to write code that is portable across platforms.\n",
      "\n",
      "6. **Interpreted Language**  \n",
      "   Python is interpreted, which means you can run code as soon as you write it without a separate compilation step, facilitating rapid development and testing.\n",
      "\n",
      "7. **Dynamic Typing**  \n",
      "   Variables in Python do not require a fixed data type, giving flexibility and reducing boilerplate code.\n",
      "\n",
      "8. **Strong Community Support**  \n",
      "   Python has a large and active community which means ample resources for learning, troubleshooting, and collaboration.\n",
      "\n",
      "9. **Versatility**  \n",
      "   Python can be used for a wide variety of applications, from simple scripting and automation to complex web applications and scientific research.\n",
      "\n",
      "10. **Integration Capabilities**  \n",
      "    Python can easily integrate with other languages like C, C++, and Java, and can be embedded into other applications.\n",
      "\n",
      "These advantages make Python a very attractive language for many different programming tasks and have helped it become one of the most popular programming languages in the world.\n",
      "\n",
      "Response 3: Certainly! Here's a simple example in Python that demonstrates defining a function, using a loop, and printing output. This program asks the user for their name and then greets them several times.\n",
      "\n",
      "```python\n",
      "def greet(name, times):\n",
      "    for i in range(times):\n",
      "        print(f\"Hello, {name}! ({i+1})\")\n",
      "\n",
      "# Ask the user for their name\n",
      "user_name = input(\"Enter your name: \")\n",
      "\n",
      "# Greet the user 3 times\n",
      "greet(user_name, 3)\n",
      "```\n",
      "\n",
      "### What this code does:\n",
      "- Defines a function `greet` that takes a `name` and a number of `times` to greet.\n",
      "- Uses a `for` loop to print a greeting multiple times.\n",
      "- Takes input from the user with `input()`.\n",
      "- Calls the function to greet the user 3 times.\n",
      "\n",
      "If you run this code, it will prompt you to enter your name, then print a personalized greeting three times. Let me know if you'd like examples for other concepts!\n",
      "\n",
      "Total messages in conversation: 6\n"
     ]
    }
   ],
   "source": [
    "class ConversationMemory:\n",
    "    \"\"\"\n",
    "    A simple conversation memory class to manage chat history.\n",
    "    In production, you might want to store this in a database or Redis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "        self.client = get_azure_openai_client()\n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    def add_user_message(self, content: str):\n",
    "        \"\"\"Add a user message to the conversation history.\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "    \n",
    "    def add_assistant_message(self, content: str):\n",
    "        \"\"\"Add an assistant message to the conversation history.\"\"\"\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "    \n",
    "    def get_response(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Get a response from Azure OpenAI while maintaining conversation context.\n",
    "        \n",
    "        Args:\n",
    "            user_input: The user's input message\n",
    "            \n",
    "        Returns:\n",
    "            Assistant's response\n",
    "        \"\"\"\n",
    "        # Add user message to history\n",
    "        self.add_user_message(user_input)\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment_name,\n",
    "                messages=self.messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000,\n",
    "            )\n",
    "            \n",
    "            assistant_response = response.choices[0].message.content\n",
    "            \n",
    "            # Add assistant response to history\n",
    "            self.add_assistant_message(assistant_response)\n",
    "            \n",
    "            return assistant_response\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: Unable to process request. {str(e)}\"\n",
    "            self.add_assistant_message(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        self.messages = []\n",
    "    \n",
    "    def get_message_count(self) -> int:\n",
    "        \"\"\"Get the number of messages in the conversation history.\"\"\"\n",
    "        return len(self.messages)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Memory Demo ===\\n\")\n",
    "    \n",
    "    # First: Ask for a joke without memory\n",
    "    print(\"1. Asking for a joke...\")\n",
    "    joke_response = ask_joke_without_memory()\n",
    "    print(f\"Response: {joke_response}\\n\")\n",
    "\n",
    "    # Second: Ask follow-up without memory (AI will be confused)\n",
    "    print(\"2. Asking follow-up without memory...\")\n",
    "    confused_response = ask_followup_without_memory()\n",
    "    print(f\"Response: {confused_response}\\n\")\n",
    "\n",
    "    # Third: Ask follow-up with memory (AI will remember)\n",
    "    print(\"3. Asking follow-up with memory...\")\n",
    "    memory_response = ask_followup_with_memory(joke_response)\n",
    "    print(f\"Response: {memory_response}\\n\")\n",
    "    \n",
    "    # Fourth: Demonstrate conversation memory class\n",
    "    print(\"4. Using ConversationMemory class...\")\n",
    "    conversation = ConversationMemory()\n",
    "    \n",
    "    # Have a multi-turn conversation\n",
    "    response1 = conversation.get_response(\"Tell me about Python programming\")\n",
    "    print(f\"Response 1: {response1}\\n\")\n",
    "    \n",
    "    response2 = conversation.get_response(\"What are its main advantages?\")\n",
    "    print(f\"Response 2: {response2}\\n\")\n",
    "    \n",
    "    response3 = conversation.get_response(\"Can you give me a simple example?\")\n",
    "    print(f\"Response 3: {response3}\\n\")\n",
    "    \n",
    "    print(f\"Total messages in conversation: {conversation.get_message_count()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
