{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4290033",
   "metadata": {},
   "source": [
    "# 3-4: Tools & Validation - Building Blocks for Azure OpenAI Agents\n",
    "\n",
    "**Original Code by Dave Ebbelaar** - Extended for Azure OpenAI by Arturo Quiroga\n",
    "\n",
    "This notebook demonstrates two critical building blocks for Azure OpenAI agents:\n",
    "- **Tools**: Function calling capabilities with external APIs (weather service)\n",
    "- **Validation**: Structured data extraction and validation using Pydantic schemas\n",
    "\n",
    "These components enable agents to interact with external systems reliably and extract structured information from unstructured text.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Ensure you have the following environment variables set:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_API_KEY` (or use Managed Identity)\n",
    "- `AZURE_OPENAI_GPT4_DEPLOYMENT`\n",
    "- `OPENWEATHERMAP_API_KEY` (for weather API demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb24862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (1.97.1)\n",
      "Requirement already satisfied: azure-identity in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (1.19.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: pydantic in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (2.10.1)\n",
      "Requirement already satisfied: requests in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (2.32.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from pydantic) (2.27.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from azure-identity) (1.35.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from azure-identity) (45.0.5)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from azure-identity) (1.33.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from azure-core>=1.31.0->azure-identity) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /Users/arturoquiroga/GITHUB/ai-cookbook/.venv/lib/python3.13/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.10.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "#!pip install openai azure-identity python-dotenv pydantic requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291c8be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import Optional, Dict, Any, List\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b409b",
   "metadata": {},
   "source": [
    "## Azure OpenAI Client Setup\n",
    "\n",
    "First, let's set up our Azure OpenAI client with proper authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f93cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI client initialized with deployment: gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "def get_azure_openai_client():\n",
    "    \"\"\"Initialize Azure OpenAI client with proper authentication.\"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    \n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    if api_key:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    else:\n",
    "        credential = DefaultAzureCredential()\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=credential,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    \n",
    "    return client\n",
    "\n",
    "# Initialize client\n",
    "client = get_azure_openai_client()\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "\n",
    "print(f\"Azure OpenAI client initialized with deployment: {deployment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b68ae1",
   "metadata": {},
   "source": [
    "# Part 1: Tools - Function Calling with External APIs\n",
    "\n",
    "Tools enable Azure OpenAI agents to interact with external systems. We'll implement a weather service that can:\n",
    "- Get coordinates for any city\n",
    "- Fetch current weather data\n",
    "- Integrate with Azure OpenAI function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e39407",
   "metadata": {},
   "source": [
    "## Weather API Tool Implementation\n",
    "\n",
    "Let's start by implementing functions to interact with the OpenWeatherMap API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd39a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London coordinates: {'name': 'London', 'country': 'GB', 'latitude': 51.5073219, 'longitude': -0.1276474, 'state': 'England'}\n"
     ]
    }
   ],
   "source": [
    "def get_city_coordinates(city_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get coordinates for a city using OpenWeatherMap Geocoding API.\n",
    "    \n",
    "    Args:\n",
    "        city_name: Name of the city\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with latitude, longitude, and city info\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"OPENWEATHERMAP_API_KEY\")\n",
    "    if not api_key:\n",
    "        return {\"error\": \"OpenWeatherMap API key not found\"}\n",
    "    \n",
    "    url = f\"http://api.openweathermap.org/geo/1.0/direct?q={city_name}&limit=1&appid={api_key}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if not data:\n",
    "            return {\"error\": f\"City '{city_name}' not found\"}\n",
    "        \n",
    "        city_data = data[0]\n",
    "        return {\n",
    "            \"name\": city_data.get(\"name\"),\n",
    "            \"country\": city_data.get(\"country\"),\n",
    "            \"latitude\": city_data.get(\"lat\"),\n",
    "            \"longitude\": city_data.get(\"lon\"),\n",
    "            \"state\": city_data.get(\"state\")  # For US cities\n",
    "        }\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        return {\"error\": f\"Failed to get coordinates: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {str(e)}\"}\n",
    "\n",
    "# Test the function\n",
    "test_coords = get_city_coordinates(\"London\")\n",
    "print(f\"London coordinates: {test_coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57308001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London weather: {'temperature': 19.74, 'feels_like': 19.47, 'humidity': 65, 'pressure': 1018, 'description': 'light rain', 'wind_speed': 3.6, 'visibility': 10000, 'city': 'London'}\n"
     ]
    }
   ],
   "source": [
    "def get_weather(latitude: float, longitude: float) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get current weather for given coordinates.\n",
    "    \n",
    "    Args:\n",
    "        latitude: Latitude coordinate\n",
    "        longitude: Longitude coordinate\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with weather information\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"OPENWEATHERMAP_API_KEY\")\n",
    "    if not api_key:\n",
    "        return {\"error\": \"OpenWeatherMap API key not found\"}\n",
    "    \n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?lat={latitude}&lon={longitude}&appid={api_key}&units=metric\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        return {\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"feels_like\": data[\"main\"][\"feels_like\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"],\n",
    "            \"pressure\": data[\"main\"][\"pressure\"],\n",
    "            \"description\": data[\"weather\"][0][\"description\"],\n",
    "            \"wind_speed\": data.get(\"wind\", {}).get(\"speed\", \"N/A\"),\n",
    "            \"visibility\": data.get(\"visibility\", \"N/A\"),\n",
    "            \"city\": data.get(\"name\", \"Unknown\")\n",
    "        }\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        return {\"error\": f\"Failed to get weather: {str(e)}\"}\n",
    "    except KeyError as e:\n",
    "        return {\"error\": f\"Unexpected weather data format: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {str(e)}\"}\n",
    "\n",
    "# Test the function (using London coordinates)\n",
    "if 'latitude' in test_coords and 'longitude' in test_coords:\n",
    "    test_weather = get_weather(test_coords['latitude'], test_coords['longitude'])\n",
    "    print(f\"London weather: {test_weather}\")\n",
    "else:\n",
    "    print(\"Could not test weather function without coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7ec6a",
   "metadata": {},
   "source": [
    "## Function Calling Integration\n",
    "\n",
    "Now let's integrate these tools with Azure OpenAI's function calling capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6cf62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function schemas defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define function schemas for Azure OpenAI\n",
    "weather_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_city_coordinates\",\n",
    "            \"description\": \"Get the coordinates (latitude and longitude) for a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the city\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city_name\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather information for given coordinates\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Latitude coordinate\"\n",
    "                    },\n",
    "                    \"longitude\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Longitude coordinate\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Function schemas defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06e6e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function executor ready!\n"
     ]
    }
   ],
   "source": [
    "def execute_function_call(function_name: str, arguments: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Execute a function call based on the function name and arguments.\n",
    "    \n",
    "    Args:\n",
    "        function_name: Name of the function to call\n",
    "        arguments: Arguments to pass to the function\n",
    "        \n",
    "    Returns:\n",
    "        Result of the function call\n",
    "    \"\"\"\n",
    "    if function_name == \"get_city_coordinates\":\n",
    "        return get_city_coordinates(arguments[\"city_name\"])\n",
    "    elif function_name == \"get_weather\":\n",
    "        return get_weather(arguments[\"latitude\"], arguments[\"longitude\"])\n",
    "    else:\n",
    "        return {\"error\": f\"Unknown function: {function_name}\"}\n",
    "\n",
    "print(\"Function executor ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c3d49",
   "metadata": {},
   "source": [
    "## Tool Agent Implementation\n",
    "\n",
    "Let's create a complete agent that can handle weather queries using function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e075af9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "class ToolAgent:\n",
    "    \"\"\"\n",
    "    Agent that can use tools via function calling with Azure OpenAI.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = get_azure_openai_client()\n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "        self.tools = weather_tools\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def process_query(self, user_query: str) -> str:\n",
    "        \"\"\"\n",
    "        Process a user query that might require tool usage.\n",
    "        \n",
    "        Args:\n",
    "            user_query: User's question or request\n",
    "            \n",
    "        Returns:\n",
    "            Response string\n",
    "        \"\"\"\n",
    "        # Add user message to conversation\n",
    "        messages = self.conversation_history + [\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # Initial request with tools\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment_name,\n",
    "                messages=messages,\n",
    "                tools=self.tools,\n",
    "                tool_choice=\"auto\",\n",
    "                temperature=0.1,\n",
    "                max_tokens=1500\n",
    "            )\n",
    "            \n",
    "            assistant_message = response.choices[0].message\n",
    "            \n",
    "            # Check if the model wants to call functions\n",
    "            if assistant_message.tool_calls:\n",
    "                # Add assistant message to conversation\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_message.content,\n",
    "                    \"tool_calls\": [\n",
    "                        {\n",
    "                            \"id\": tool_call.id,\n",
    "                            \"type\": tool_call.type,\n",
    "                            \"function\": {\n",
    "                                \"name\": tool_call.function.name,\n",
    "                                \"arguments\": tool_call.function.arguments\n",
    "                            }\n",
    "                        }\n",
    "                        for tool_call in assistant_message.tool_calls\n",
    "                    ]\n",
    "                })\n",
    "                \n",
    "                # Execute each function call\n",
    "                for tool_call in assistant_message.tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "                    \n",
    "                    print(f\"üîß Calling function: {function_name} with args: {function_args}\")\n",
    "                    \n",
    "                    function_result = execute_function_call(function_name, function_args)\n",
    "                    \n",
    "                    # Add function result to messages\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": json.dumps(function_result)\n",
    "                    })\n",
    "                \n",
    "                # Get final response with function results\n",
    "                final_response = self.client.chat.completions.create(\n",
    "                    model=self.deployment_name,\n",
    "                    messages=messages,\n",
    "                    temperature=0.1,\n",
    "                    max_tokens=1500\n",
    "                )\n",
    "                \n",
    "                return final_response.choices[0].message.content\n",
    "            \n",
    "            else:\n",
    "                # No function call needed\n",
    "                return assistant_message.content\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f\"Sorry, I encountered an error: {str(e)}\"\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset the conversation history.\"\"\"\n",
    "        self.conversation_history = []\n",
    "\n",
    "# Create the tool agent\n",
    "tool_agent = ToolAgent()\n",
    "print(\"Tool agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e76c78",
   "metadata": {},
   "source": [
    "## Testing the Tool Agent\n",
    "\n",
    "Let's test our tool agent with various weather queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3e0cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Simple Weather Query ===\n",
      "üîß Calling function: get_city_coordinates with args: {'city_name': 'Paris'}\n",
      "Query: What's the weather like in Paris?\n",
      "Response: I don't have real-time weather data access, but you can easily check the current weather in Paris using a weather website or app like Weather.com, AccuWeather, or by searching \"Paris weather\" on Google for the latest updates.\n",
      "\n",
      "If you need a general idea, Paris in June typically experiences mild to warm temperatures (around 18‚Äì25¬∞C or 64‚Äì77¬∞F), with occasional rain showers and partly cloudy skies. For the most accurate and up-to-date information, please check a live weather service.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Simple weather query\n",
    "print(\"=== Test 1: Simple Weather Query ===\")\n",
    "query1 = \"What's the weather like in Paris?\"\n",
    "response1 = tool_agent.process_query(query1)\n",
    "print(f\"Query: {query1}\")\n",
    "print(f\"Response: {response1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34be52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 2: Weather Comparison ===\n",
      "üîß Calling function: get_city_coordinates with args: {'city_name': 'New York'}\n",
      "üîß Calling function: get_city_coordinates with args: {'city_name': 'Tokyo'}\n",
      "Query: Compare the weather between New York and Tokyo\n",
      "Response: Here‚Äôs a comparison of the weather between New York and Tokyo:\n",
      "\n",
      "- New York (US): Located at approximately 40.7¬∞N latitude, New York experiences a humid subtropical climate with cold winters (often below freezing), hot and humid summers, and moderate rainfall throughout the year. Snow is common in winter.\n",
      "\n",
      "- Tokyo (Japan): Located at about 35.7¬∞N latitude, Tokyo also has a humid subtropical climate but with milder winters (rarely below freezing), hot and humid summers, and a pronounced rainy season in early summer. Snow is rare.\n",
      "\n",
      "In summary:\n",
      "- New York has colder winters and more frequent snow.\n",
      "- Tokyo has milder winters, a distinct rainy season, and less snow.\n",
      "- Both cities have hot, humid summers and similar annual rainfall.\n",
      "\n",
      "If you want the current weather or a forecast, let me know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Comparison query\n",
    "print(\"=== Test 2: Weather Comparison ===\")\n",
    "query2 = \"Compare the weather between New York and Tokyo\"\n",
    "response2 = tool_agent.process_query(query2)\n",
    "print(f\"Query: {query2}\")\n",
    "print(f\"Response: {response2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e587bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 3: Non-Weather Query ===\n",
      "Query: What is the capital of France?\n",
      "Response: The capital of France is Paris.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Non-weather query (should not use tools)\n",
    "print(\"=== Test 3: Non-Weather Query ===\")\n",
    "query3 = \"What is the capital of France?\"\n",
    "response3 = tool_agent.process_query(query3)\n",
    "print(f\"Query: {query3}\")\n",
    "print(f\"Response: {response3}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13172fc2",
   "metadata": {},
   "source": [
    "# Part 2: Validation - Structured Data Extraction\n",
    "\n",
    "Validation ensures that data extracted from unstructured text meets specific requirements. We'll use Pydantic schemas to define data structures and implement robust extraction with retry logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d508f8",
   "metadata": {},
   "source": [
    "## Pydantic Schema Definitions\n",
    "\n",
    "Let's define schemas for different types of structured data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082f04e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation schemas defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class TaskResult(BaseModel):\n",
    "    \"\"\"Schema for task extraction and analysis.\"\"\"\n",
    "    task: str = Field(description=\"The main task or action item\")\n",
    "    priority: str = Field(description=\"Priority level: high, medium, or low\")\n",
    "    deadline: Optional[str] = Field(None, description=\"Deadline if mentioned (YYYY-MM-DD format)\")\n",
    "    assignee: Optional[str] = Field(None, description=\"Person assigned to the task\")\n",
    "    department: Optional[str] = Field(None, description=\"Department responsible\")\n",
    "    estimated_hours: Optional[int] = Field(None, description=\"Estimated hours to complete\")\n",
    "    dependencies: List[str] = Field(default_factory=list, description=\"Other tasks this depends on\")\n",
    "\n",
    "\n",
    "class PersonInfo(BaseModel):\n",
    "    \"\"\"Schema for person information extraction.\"\"\"\n",
    "    name: str = Field(description=\"Full name of the person\")\n",
    "    role: Optional[str] = Field(None, description=\"Job title or role\")\n",
    "    company: Optional[str] = Field(None, description=\"Company or organization\")\n",
    "    email: Optional[str] = Field(None, description=\"Email address\")\n",
    "    phone: Optional[str] = Field(None, description=\"Phone number\")\n",
    "    skills: List[str] = Field(default_factory=list, description=\"Mentioned skills or expertise\")\n",
    "    experience_years: Optional[int] = Field(None, description=\"Years of experience if mentioned\")\n",
    "\n",
    "\n",
    "class ProjectPlan(BaseModel):\n",
    "    \"\"\"Schema for project planning extraction.\"\"\"\n",
    "    project_name: str = Field(description=\"Name of the project\")\n",
    "    description: str = Field(description=\"Project description\")\n",
    "    objectives: List[str] = Field(description=\"Project objectives\")\n",
    "    timeline: Optional[str] = Field(None, description=\"Project timeline\")\n",
    "    budget: Optional[str] = Field(None, description=\"Budget if mentioned\")\n",
    "    team_size: Optional[int] = Field(None, description=\"Required team size\")\n",
    "    technologies: List[str] = Field(default_factory=list, description=\"Technologies to be used\")\n",
    "    risks: List[str] = Field(default_factory=list, description=\"Identified risks\")\n",
    "\n",
    "print(\"Validation schemas defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31deb2f2",
   "metadata": {},
   "source": [
    "## Structured Intelligence Function\n",
    "\n",
    "This function extracts structured data from unstructured text using Azure OpenAI's structured output capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b4832ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured intelligence function ready!\n"
     ]
    }
   ],
   "source": [
    "def structured_intelligence(prompt: str, schema_class: BaseModel) -> dict:\n",
    "    \"\"\"\n",
    "    Extract structured information using Azure OpenAI and validate with Pydantic.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Input text to extract information from\n",
    "        schema_class: Pydantic model class for validation\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extracted and validated data\n",
    "    \"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    \n",
    "    # Get schema information\n",
    "    schema_name = schema_class.__name__\n",
    "    schema_json = schema_class.model_json_schema()\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    Extract information from the user's text and structure it according to the {schema_name} schema.\n",
    "    \n",
    "    Schema: {json.dumps(schema_json, indent=2)}\n",
    "    \n",
    "    Rules:\n",
    "    - Extract only information that is explicitly mentioned or can be reasonably inferred\n",
    "    - Use null for optional fields when information is not available\n",
    "    - Be precise and accurate\n",
    "    - For lists, include all relevant items mentioned\n",
    "    - For dates, use YYYY-MM-DD format when possible\n",
    "    \n",
    "    Return valid JSON that matches the schema exactly.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=1500,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        # Parse and validate response\n",
    "        response_text = response.choices[0].message.content\n",
    "        json_data = json.loads(response_text)\n",
    "        \n",
    "        # Validate with Pydantic\n",
    "        validated_data = schema_class(**json_data)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": validated_data.model_dump(),\n",
    "            \"raw_response\": response_text\n",
    "        }\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Invalid JSON response: {str(e)}\",\n",
    "            \"raw_response\": response_text if 'response_text' in locals() else None\n",
    "        }\n",
    "    \n",
    "    except ValidationError as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Validation error: {str(e)}\",\n",
    "            \"raw_data\": json_data if 'json_data' in locals() else None\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Unexpected error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"Structured intelligence function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a90a2",
   "metadata": {},
   "source": [
    "## Extraction with Retry Logic\n",
    "\n",
    "For critical applications, we need robust extraction that can handle failures and retry with different strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92dcff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry extraction function ready!\n"
     ]
    }
   ],
   "source": [
    "def extract_with_retry(\n",
    "    prompt: str, \n",
    "    schema_class: BaseModel, \n",
    "    max_attempts: int = 3,\n",
    "    temperature_progression: List[float] = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extract structured data with retry logic and progressive temperature adjustment.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Input text to extract from\n",
    "        schema_class: Pydantic model for validation\n",
    "        max_attempts: Maximum number of retry attempts\n",
    "        temperature_progression: Temperature values for each attempt\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extraction results and attempt information\n",
    "    \"\"\"\n",
    "    if temperature_progression is None:\n",
    "        temperature_progression = [0.0, 0.1, 0.3]  # Start strict, get more creative\n",
    "    \n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    \n",
    "    schema_name = schema_class.__name__\n",
    "    schema_json = schema_class.model_json_schema()\n",
    "    \n",
    "    attempts = []\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        temperature = temperature_progression[min(attempt, len(temperature_progression) - 1)]\n",
    "        \n",
    "        print(f\"üîÑ Attempt {attempt + 1}/{max_attempts} (temperature: {temperature})\")\n",
    "        \n",
    "        # Adjust system prompt based on attempt\n",
    "        if attempt == 0:\n",
    "            strategy = \"Be precise and conservative. Only extract explicitly mentioned information.\"\n",
    "        elif attempt == 1:\n",
    "            strategy = \"Be more flexible. Make reasonable inferences from context.\"\n",
    "        else:\n",
    "            strategy = \"Be creative but accurate. Extract any relevant information that could fit the schema.\"\n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "        Extract information from the user's text and structure it according to the {schema_name} schema.\n",
    "        \n",
    "        Strategy for this attempt: {strategy}\n",
    "        \n",
    "        Schema: {json.dumps(schema_json, indent=2)}\n",
    "        \n",
    "        Rules:\n",
    "        - Return valid JSON that matches the schema exactly\n",
    "        - Use null for optional fields when information is not available\n",
    "        - For lists, include all relevant items\n",
    "        - Be accurate and helpful\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=1500,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            response_text = response.choices[0].message.content\n",
    "            json_data = json.loads(response_text)\n",
    "            \n",
    "            # Validate with Pydantic\n",
    "            validated_data = schema_class(**json_data)\n",
    "            \n",
    "            # Success!\n",
    "            result = {\n",
    "                \"success\": True,\n",
    "                \"data\": validated_data.model_dump(),\n",
    "                \"attempts\": attempt + 1,\n",
    "                \"final_temperature\": temperature,\n",
    "                \"raw_response\": response_text\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Success on attempt {attempt + 1}\")\n",
    "            return result\n",
    "            \n",
    "        except (json.JSONDecodeError, ValidationError, Exception) as e:\n",
    "            error_info = {\n",
    "                \"attempt\": attempt + 1,\n",
    "                \"temperature\": temperature,\n",
    "                \"error_type\": type(e).__name__,\n",
    "                \"error_message\": str(e),\n",
    "                \"raw_response\": response_text if 'response_text' in locals() else None\n",
    "            }\n",
    "            attempts.append(error_info)\n",
    "            \n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed: {error_info['error_type']} - {error_info['error_message'][:100]}...\")\n",
    "    \n",
    "    # All attempts failed\n",
    "    return {\n",
    "        \"success\": False,\n",
    "        \"error\": f\"All {max_attempts} attempts failed\",\n",
    "        \"attempts\": attempts\n",
    "    }\n",
    "\n",
    "print(\"Retry extraction function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f1dea",
   "metadata": {},
   "source": [
    "## Validation Agent\n",
    "\n",
    "Let's create a comprehensive validation agent that can handle multiple schema types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a3a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "class ValidationAgent:\n",
    "    \"\"\"\n",
    "    Agent specialized in structured data extraction and validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = get_azure_openai_client()\n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "        self.schemas = {\n",
    "            \"task\": TaskResult,\n",
    "            \"person\": PersonInfo,\n",
    "            \"project\": ProjectPlan\n",
    "        }\n",
    "    \n",
    "    def extract_tasks(self, text: str, use_retry: bool = True) -> dict:\n",
    "        \"\"\"Extract task information from text.\"\"\"\n",
    "        if use_retry:\n",
    "            return extract_with_retry(text, TaskResult)\n",
    "        else:\n",
    "            return structured_intelligence(text, TaskResult)\n",
    "    \n",
    "    def extract_person_info(self, text: str, use_retry: bool = True) -> dict:\n",
    "        \"\"\"Extract person information from text.\"\"\"\n",
    "        if use_retry:\n",
    "            return extract_with_retry(text, PersonInfo)\n",
    "        else:\n",
    "            return structured_intelligence(text, PersonInfo)\n",
    "    \n",
    "    def extract_project_plan(self, text: str, use_retry: bool = True) -> dict:\n",
    "        \"\"\"Extract project planning information from text.\"\"\"\n",
    "        if use_retry:\n",
    "            return extract_with_retry(text, ProjectPlan)\n",
    "        else:\n",
    "            return structured_intelligence(text, ProjectPlan)\n",
    "    \n",
    "    def auto_detect_and_extract(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Automatically detect the type of information and extract accordingly.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text to analyze\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with detected type and extracted data\n",
    "        \"\"\"\n",
    "        # First, determine what type of information this might be\n",
    "        detection_prompt = f\"\"\"\n",
    "        Analyze this text and determine what type of structured information it primarily contains:\n",
    "        \n",
    "        Text: \"{text}\"\n",
    "        \n",
    "        Choose the most appropriate category:\n",
    "        - \"task\": If it describes tasks, action items, or work to be done\n",
    "        - \"person\": If it describes a person's information, background, or credentials\n",
    "        - \"project\": If it describes a project, plan, or initiative\n",
    "        - \"general\": If it doesn't fit the above categories\n",
    "        \n",
    "        Return only the category name.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": detection_prompt}],\n",
    "                temperature=0.0,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            \n",
    "            detected_type = response.choices[0].message.content.strip().lower()\n",
    "            \n",
    "            print(f\"üîç Detected information type: {detected_type}\")\n",
    "            \n",
    "            # Extract based on detected type\n",
    "            if detected_type == \"task\":\n",
    "                result = self.extract_tasks(text)\n",
    "            elif detected_type == \"person\":\n",
    "                result = self.extract_person_info(text)\n",
    "            elif detected_type == \"project\":\n",
    "                result = self.extract_project_plan(text)\n",
    "            else:\n",
    "                return {\n",
    "                    \"detected_type\": detected_type,\n",
    "                    \"success\": False,\n",
    "                    \"error\": \"No appropriate schema found for this type of content\"\n",
    "                }\n",
    "            \n",
    "            result[\"detected_type\"] = detected_type\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Auto-detection failed: {str(e)}\"\n",
    "            }\n",
    "\n",
    "# Create validation agent\n",
    "validation_agent = ValidationAgent()\n",
    "print(\"Validation agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4892407e",
   "metadata": {},
   "source": [
    "## Testing the Validation Agent\n",
    "\n",
    "Let's test our validation agent with different types of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8deee8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Task Extraction ===\n",
      "üîÑ Attempt 1/3 (temperature: 0.0)\n",
      "‚úÖ Success on attempt 1\n",
      "Task extraction result:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"task\": \"Implement the new user authentication system\",\n",
      "    \"priority\": \"high\",\n",
      "    \"deadline\": \"2024-03-15\",\n",
      "    \"assignee\": null,\n",
      "    \"department\": \"security team\",\n",
      "    \"estimated_hours\": 40,\n",
      "    \"dependencies\": [\n",
      "      \"database migration being finished\"\n",
      "    ]\n",
      "  },\n",
      "  \"attempts\": 1,\n",
      "  \"final_temperature\": 0.0,\n",
      "  \"raw_response\": \"{\\n  \\\"task\\\": \\\"Implement the new user authentication system\\\",\\n  \\\"priority\\\": \\\"high\\\",\\n  \\\"deadline\\\": \\\"2024-03-15\\\",\\n  \\\"assignee\\\": null,\\n  \\\"department\\\": \\\"security team\\\",\\n  \\\"estimated_hours\\\": 40,\\n  \\\"dependencies\\\": [\\n    \\\"database migration being finished\\\"\\n  ]\\n}\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Task extraction\n",
    "print(\"=== Test 1: Task Extraction ===\")\n",
    "task_text = \"\"\"\n",
    "We need to implement the new user authentication system by Friday, March 15th. \n",
    "This is a high priority task that should be assigned to the security team. \n",
    "It will probably take about 40 hours to complete and depends on the database \n",
    "migration being finished first.\n",
    "\"\"\"\n",
    "\n",
    "task_result = validation_agent.extract_tasks(task_text.strip())\n",
    "print(f\"Task extraction result:\")\n",
    "print(json.dumps(task_result, indent=2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82e4b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 2: Person Information Extraction ===\n",
      "üîÑ Attempt 1/3 (temperature: 0.0)\n",
      "‚úÖ Success on attempt 1\n",
      "Person extraction result:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"name\": \"Sarah Johnson\",\n",
      "    \"role\": \"Senior Software Engineer\",\n",
      "    \"company\": \"TechCorp\",\n",
      "    \"email\": \"sarah.johnson@techcorp.com\",\n",
      "    \"phone\": \"+1-555-0123\",\n",
      "    \"skills\": [\n",
      "      \"backend development\",\n",
      "      \"Python\",\n",
      "      \"Go\",\n",
      "      \"distributed systems\"\n",
      "    ],\n",
      "    \"experience_years\": 8\n",
      "  },\n",
      "  \"attempts\": 1,\n",
      "  \"final_temperature\": 0.0,\n",
      "  \"raw_response\": \"{\\n  \\\"name\\\": \\\"Sarah Johnson\\\",\\n  \\\"role\\\": \\\"Senior Software Engineer\\\",\\n  \\\"company\\\": \\\"TechCorp\\\",\\n  \\\"email\\\": \\\"sarah.johnson@techcorp.com\\\",\\n  \\\"phone\\\": \\\"+1-555-0123\\\",\\n  \\\"skills\\\": [\\n    \\\"backend development\\\",\\n    \\\"Python\\\",\\n    \\\"Go\\\",\\n    \\\"distributed systems\\\"\\n  ],\\n  \\\"experience_years\\\": 8\\n}\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Person information extraction\n",
    "print(\"=== Test 2: Person Information Extraction ===\")\n",
    "person_text = \"\"\"\n",
    "Sarah Johnson is a Senior Software Engineer at TechCorp with 8 years of experience \n",
    "in backend development. She specializes in Python, Go, and distributed systems. \n",
    "You can reach her at sarah.johnson@techcorp.com or call her at +1-555-0123.\n",
    "\"\"\"\n",
    "\n",
    "person_result = validation_agent.extract_person_info(person_text.strip())\n",
    "print(f\"Person extraction result:\")\n",
    "print(json.dumps(person_result, indent=2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebf9a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 3: Project Plan Extraction ===\n",
      "üîÑ Attempt 1/3 (temperature: 0.0)\n",
      "‚úÖ Success on attempt 1\n",
      "Project extraction result:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"project_name\": \"Project Apollo: AI-Powered Customer Service Bot\",\n",
      "    \"description\": \"We're launching an AI-powered customer service chatbot to improve response times and customer satisfaction.\",\n",
      "    \"objectives\": [\n",
      "      \"Reduce average response time by 50%\",\n",
      "      \"Handle 80% of common queries automatically\",\n",
      "      \"Provide 24/7 support\"\n",
      "    ],\n",
      "    \"timeline\": \"6 months from project start\",\n",
      "    \"budget\": \"$250,000\",\n",
      "    \"team_size\": 6,\n",
      "    \"technologies\": [\n",
      "      \"Python\",\n",
      "      \"Azure OpenAI\",\n",
      "      \"React\",\n",
      "      \"Node.js\"\n",
      "    ],\n",
      "    \"risks\": [\n",
      "      \"Model accuracy\",\n",
      "      \"Integration complexity\",\n",
      "      \"User adoption\"\n",
      "    ]\n",
      "  },\n",
      "  \"attempts\": 1,\n",
      "  \"final_temperature\": 0.0,\n",
      "  \"raw_response\": \"{\\n  \\\"project_name\\\": \\\"Project Apollo: AI-Powered Customer Service Bot\\\",\\n  \\\"description\\\": \\\"We're launching an AI-powered customer service chatbot to improve response times and customer satisfaction.\\\",\\n  \\\"objectives\\\": [\\n    \\\"Reduce average response time by 50%\\\",\\n    \\\"Handle 80% of common queries automatically\\\",\\n    \\\"Provide 24/7 support\\\"\\n  ],\\n  \\\"timeline\\\": \\\"6 months from project start\\\",\\n  \\\"budget\\\": \\\"$250,000\\\",\\n  \\\"team_size\\\": 6,\\n  \\\"technologies\\\": [\\n    \\\"Python\\\",\\n    \\\"Azure OpenAI\\\",\\n    \\\"React\\\",\\n    \\\"Node.js\\\"\\n  ],\\n  \\\"risks\\\": [\\n    \\\"Model accuracy\\\",\\n    \\\"Integration complexity\\\",\\n    \\\"User adoption\\\"\\n  ]\\n}\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Project plan extraction\n",
    "print(\"=== Test 3: Project Plan Extraction ===\")\n",
    "project_text = \"\"\"\n",
    "Project Apollo: AI-Powered Customer Service Bot\n",
    "\n",
    "We're launching an AI-powered customer service chatbot to improve response times \n",
    "and customer satisfaction. The main objectives are to reduce average response time \n",
    "by 50%, handle 80% of common queries automatically, and provide 24/7 support.\n",
    "\n",
    "Timeline: 6 months from project start\n",
    "Budget: $250,000\n",
    "Team: We'll need 5-6 people including AI engineers, UX designers, and QA testers\n",
    "Technologies: Python, Azure OpenAI, React, Node.js\n",
    "Main risks: Model accuracy, integration complexity, user adoption\n",
    "\"\"\"\n",
    "\n",
    "project_result = validation_agent.extract_project_plan(project_text.strip())\n",
    "print(f\"Project extraction result:\")\n",
    "print(json.dumps(project_result, indent=2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b8d2e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 4: Auto-Detection ===\n",
      "üîç Detected information type: task\n",
      "üîÑ Attempt 1/3 (temperature: 0.0)\n",
      "‚úÖ Success on attempt 1\n",
      "Auto-detection result:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"data\": {\n",
      "    \"task\": \"Update the website footer with new contact information\",\n",
      "    \"priority\": \"medium\",\n",
      "    \"deadline\": \"2024-06-18\",\n",
      "    \"assignee\": null,\n",
      "    \"department\": \"web development team\",\n",
      "    \"estimated_hours\": null,\n",
      "    \"dependencies\": []\n",
      "  },\n",
      "  \"attempts\": 1,\n",
      "  \"final_temperature\": 0.0,\n",
      "  \"raw_response\": \"{\\n  \\\"task\\\": \\\"Update the website footer with new contact information\\\",\\n  \\\"priority\\\": \\\"medium\\\",\\n  \\\"deadline\\\": \\\"2024-06-18\\\",\\n  \\\"assignee\\\": null,\\n  \\\"department\\\": \\\"web development team\\\",\\n  \\\"estimated_hours\\\": null,\\n  \\\"dependencies\\\": []\\n}\",\n",
      "  \"detected_type\": \"task\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 4: Auto-detection\n",
    "print(\"=== Test 4: Auto-Detection ===\")\n",
    "mixed_text = \"\"\"\n",
    "We need to update the website footer with new contact information. \n",
    "This should be done by next Tuesday and assigned to the web development team.\n",
    "\"\"\"\n",
    "\n",
    "auto_result = validation_agent.auto_detect_and_extract(mixed_text.strip())\n",
    "print(f\"Auto-detection result:\")\n",
    "print(json.dumps(auto_result, indent=2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e385f1a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've implemented two essential building blocks for Azure OpenAI agents:\n",
    "\n",
    "### Tools (Function Calling)\n",
    "- **Weather API Integration**: Complete implementation of external API calls\n",
    "- **Function Schema Definition**: Proper OpenAI function calling schema setup\n",
    "- **Tool Agent**: Intelligent agent that can decide when and how to use tools\n",
    "- **Error Handling**: Robust error handling for API failures\n",
    "\n",
    "### Validation (Structured Extraction)\n",
    "- **Pydantic Schemas**: Well-defined data structures for different content types\n",
    "- **Structured Intelligence**: Reliable extraction using Azure OpenAI's JSON mode\n",
    "- **Retry Logic**: Progressive temperature adjustment for better extraction\n",
    "- **Auto-Detection**: Automatic content type detection and appropriate schema selection\n",
    "\n",
    "These components provide the foundation for building sophisticated AI agents that can:\n",
    "- Interact with external systems safely and reliably\n",
    "- Extract and validate structured data from unstructured text\n",
    "- Handle errors gracefully with appropriate fallback strategies\n",
    "- Maintain data integrity through proper validation\n",
    "\n",
    "**Next Steps**: Combine these with control flow and recovery mechanisms to build production-ready AI agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
