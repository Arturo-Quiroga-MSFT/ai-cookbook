{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c617bad",
   "metadata": {},
   "source": [
    "# 5-6: Control & Recovery - Advanced Flow and Resilience for Azure OpenAI Agents\n",
    "\n",
    "**Original Code by Dave Ebbelaar** - Extended for Azure OpenAI by Arturo Quiroga\n",
    "\n",
    "This notebook demonstrates two advanced building blocks for Azure OpenAI agents:\n",
    "- **Control**: Deterministic decision-making, intent classification, routing, and process orchestration\n",
    "- **Recovery**: Robust error handling, retry logic, circuit breaker, and resilience patterns\n",
    "\n",
    "These components enable agents to manage complex workflows, route requests, and recover gracefully from failures.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Ensure you have the following environment variables set:\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_API_KEY` (or use Managed Identity)\n",
    "- `AZURE_OPENAI_GPT4_DEPLOYMENT`\n",
    "\n",
    "Install required packages:\n",
    "- openai\n",
    "- azure-identity\n",
    "- python-dotenv\n",
    "- pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd793f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "#!pip install openai azure-identity python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b032ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and set up environment\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from typing import Optional, Any, Callable, List, Literal\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging for recovery components\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fbcda",
   "metadata": {},
   "source": [
    "## Azure OpenAI Client Initialization\n",
    "\n",
    "This function initializes the Azure OpenAI client using either API key or Managed Identity, following Azure best practices for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1843162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI client initialized with deployment: gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "def get_azure_openai_client():\n",
    "    \"\"\"Initialize Azure OpenAI client with proper authentication.\"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    \n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    if api_key:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    else:\n",
    "        credential = DefaultAzureCredential()\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=credential,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    \n",
    "    return client\n",
    "\n",
    "# Initialize client\n",
    "client = get_azure_openai_client()\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "print(f\"Azure OpenAI client initialized with deployment: {deployment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bbf81",
   "metadata": {},
   "source": [
    "# 1. Intent Classification Implementation\n",
    "\n",
    "We use a Pydantic schema to classify user input into one of several intent categories, with confidence and reasoning. This enables downstream routing and control logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e905d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassification(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for intent classification results.\n",
    "    \"\"\"\n",
    "    intent: Literal[\"question\", \"request\", \"complaint\", \"greeting\", \"goodbye\"] = Field(\n",
    "        description=\"The classified intent of the user input\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        ge=0.0, le=1.0, \n",
    "        description=\"Confidence score between 0 and 1\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Explanation for the classification decision\"\n",
    "    )\n",
    "    entities: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Key entities extracted from the input\"\n",
    "    )\n",
    "\n",
    "def classify_intent(user_input: str) -> IntentClassification:\n",
    "    \"\"\"\n",
    "    Classify user input into predefined intent categories using Azure OpenAI.\n",
    "    \"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    Classify the user input into one of these intents: question, request, complaint, greeting, goodbye.\n",
    "    Return JSON in this format:\n",
    "    {\"intent\": \"...\", \"confidence\": 0.95, \"reasoning\": \"...\", \"entities\": [\"...\"]}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input},\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=800,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        response_text = response.choices[0].message.content\n",
    "        json_data = json.loads(response_text)\n",
    "        return IntentClassification(**json_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Intent classification error: {e}\")\n",
    "        return IntentClassification(\n",
    "            intent=\"question\",\n",
    "            confidence=0.0,\n",
    "            reasoning=f\"Error in classification: {str(e)}\",\n",
    "            entities=[]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d393bd",
   "metadata": {},
   "source": [
    "# 2. Request Routing System\n",
    "\n",
    "This schema and function route requests to the appropriate department and assign a priority, based on the classified intent and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8304444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingDecision(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for routing decisions.\n",
    "    \"\"\"\n",
    "    department: Literal[\"sales\", \"support\", \"billing\", \"technical\", \"general\"] = Field(\n",
    "        description=\"Department to route the request to\"\n",
    "    )\n",
    "    priority: Literal[\"low\", \"medium\", \"high\", \"urgent\"] = Field(\n",
    "        description=\"Priority level of the request\"\n",
    "    )\n",
    "    requires_human: bool = Field(\n",
    "        description=\"Whether human intervention is required\"\n",
    "    )\n",
    "    estimated_resolution_time: str = Field(\n",
    "        description=\"Estimated time to resolve (e.g., '5 minutes', '2 hours', '1 day')\"\n",
    "    )\n",
    "\n",
    "def route_request(user_input: str, intent: IntentClassification) -> RoutingDecision:\n",
    "    \"\"\"\n",
    "    Route requests to appropriate departments based on content and intent.\n",
    "    \"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    Route this request to the appropriate department based on the content and intent.\n",
    "    User intent: {intent.intent}\n",
    "    User input: {user_input}\n",
    "    Return JSON in this format:\n",
    "    {{\"department\": \"...\", \"priority\": \"...\", \"requires_human\": true, \"estimated_resolution_time\": \"...\"}}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Route this: {user_input}\"},\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=500,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        response_text = response.choices[0].message.content\n",
    "        json_data = json.loads(response_text)\n",
    "        return RoutingDecision(**json_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Routing error: {e}\")\n",
    "        return RoutingDecision(\n",
    "            department=\"general\",\n",
    "            priority=\"medium\",\n",
    "            requires_human=True,\n",
    "            estimated_resolution_time=\"30 minutes\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff838f",
   "metadata": {},
   "source": [
    "# 3. Control Agent with Decision Trees\n",
    "\n",
    "This agent manages conversation flow, maintains history, and routes requests through proper decision trees for robust control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202f1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_greeting(user_input: str) -> str:\n",
    "    return \"Hello! How can I assist you today? I can help with questions, requests, or connect you with the right department.\"\n",
    "\n",
    "def handle_goodbye(user_input: str) -> str:\n",
    "    return \"Thank you for contacting us! Have a great day and feel free to reach out if you need anything else.\"\n",
    "\n",
    "def answer_question(question: str, routing: RoutingDecision) -> str:\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    department_context = {\n",
    "        \"sales\": \"You are a sales representative. Focus on how our products can solve their needs.\",\n",
    "        \"support\": \"You are a support agent. Provide helpful troubleshooting and guidance.\",\n",
    "        \"billing\": \"You are a billing specialist. Help with account and payment questions.\",\n",
    "        \"technical\": \"You are a technical expert. Provide detailed technical information.\",\n",
    "        \"general\": \"You are a general assistant. Provide helpful information and guidance.\"\n",
    "    }\n",
    "    context = department_context.get(routing.department, department_context[\"general\"])\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": context},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"I'm having trouble processing your question right now. Please try again or contact our {routing.department} team directly.\"\n",
    "\n",
    "def process_request(request: str, routing: RoutingDecision) -> str:\n",
    "    if routing.requires_human:\n",
    "        return f\"I've routed your request to our {routing.department} team (Priority: {routing.priority}). Expected response time: {routing.estimated_resolution_time}. Someone will get back to you soon!\"\n",
    "    else:\n",
    "        return f\"Processing your request: {request}. This has been categorized as {routing.priority} priority for the {routing.department} team.\"\n",
    "\n",
    "def handle_complaint(complaint: str, routing: RoutingDecision) -> str:\n",
    "    return f\"I understand your concern and I'm sorry you're experiencing this issue. I've escalated this to our {routing.department} team with {routing.priority} priority. Expected resolution time: {routing.estimated_resolution_time}. A specialist will contact you shortly to resolve this matter.\"\n",
    "\n",
    "def route_based_on_intent(user_input: str) -> tuple[str, IntentClassification, RoutingDecision]:\n",
    "    classification = classify_intent(user_input)\n",
    "    intent = classification.intent\n",
    "    routing = route_request(user_input, classification)\n",
    "    if intent == \"greeting\":\n",
    "        result = handle_greeting(user_input)\n",
    "    elif intent == \"goodbye\":\n",
    "        result = handle_goodbye(user_input)\n",
    "    elif intent == \"question\":\n",
    "        result = answer_question(user_input, routing)\n",
    "    elif intent == \"request\":\n",
    "        result = process_request(user_input, routing)\n",
    "    elif intent == \"complaint\":\n",
    "        result = handle_complaint(user_input, routing)\n",
    "    else:\n",
    "        result = \"I'm not sure how to help with that. Let me connect you with a human agent.\"\n",
    "    return result, classification, routing\n",
    "\n",
    "class ControlAgent:\n",
    "    \"\"\"\n",
    "    Advanced control agent that manages complex decision trees and workflows.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.client = get_azure_openai_client()\n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "        self.conversation_history = []\n",
    "    def process_input(self, user_input: str) -> dict:\n",
    "        response, classification, routing = route_based_on_intent(user_input)\n",
    "        self.conversation_history.append({\n",
    "            \"user_input\": user_input,\n",
    "            \"classification\": classification.model_dump(),\n",
    "            \"routing\": routing.model_dump(),\n",
    "            \"response\": response\n",
    "        })\n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"classification\": classification.model_dump(),\n",
    "            \"routing\": routing.model_dump(),\n",
    "            \"conversation_turn\": len(self.conversation_history)\n",
    "        }\n",
    "    def get_conversation_summary(self) -> str:\n",
    "        if not self.conversation_history:\n",
    "            return \"No conversation history yet.\"\n",
    "        intents = [turn[\"classification\"][\"intent\"] for turn in self.conversation_history]\n",
    "        departments = [turn[\"routing\"][\"department\"] for turn in self.conversation_history]\n",
    "        return f\"Conversation summary: {len(self.conversation_history)} turns, Intents: {list(set(intents))}, Departments involved: {list(set(departments))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84ab3e",
   "metadata": {},
   "source": [
    "# 4. Retry Logic and Exponential Backoff\n",
    "\n",
    "This section implements robust retry logic with exponential backoff and jitter, following Azure best practices for reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cdce61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetryConfig:\n",
    "    \"\"\"Configuration for retry logic.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_attempts: int = 3,\n",
    "        initial_delay: float = 1.0,\n",
    "        max_delay: float = 60.0,\n",
    "        exponential_base: float = 2.0,\n",
    "        jitter: bool = True\n",
    "    ):\n",
    "        self.max_attempts = max_attempts\n",
    "        self.initial_delay = initial_delay\n",
    "        self.max_delay = max_delay\n",
    "        self.exponential_base = exponential_base\n",
    "        self.jitter = jitter\n",
    "\n",
    "def exponential_backoff(attempt: int, config: RetryConfig) -> float:\n",
    "    delay = config.initial_delay * (config.exponential_base ** attempt)\n",
    "    delay = min(delay, config.max_delay)\n",
    "    if config.jitter:\n",
    "        import random\n",
    "        delay *= (0.5 + random.random() * 0.5)\n",
    "    return delay\n",
    "\n",
    "def retry_with_backoff(\n",
    "    func: Callable,\n",
    "    config: RetryConfig = None,\n",
    "    exceptions: tuple = None\n",
    ") -> Any:\n",
    "    if config is None:\n",
    "        config = RetryConfig()\n",
    "    if exceptions is None:\n",
    "        exceptions = (Exception,)\n",
    "    last_exception = None\n",
    "    for attempt in range(config.max_attempts):\n",
    "        try:\n",
    "            return func()\n",
    "        except exceptions as e:\n",
    "            last_exception = e\n",
    "            if attempt < config.max_attempts - 1:\n",
    "                delay = exponential_backoff(attempt, config)\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed: {e}. Retrying in {delay:.2f} seconds...\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                logger.error(f\"All {config.max_attempts} attempts failed. Last error: {e}\")\n",
    "    raise last_exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ad4ea",
   "metadata": {},
   "source": [
    "# 5. Resilient Intelligence with Error Handling\n",
    "\n",
    "This function demonstrates resilient intelligence with comprehensive error handling and fallback responses for Azure OpenAI calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107b93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resilient_intelligence(prompt: str) -> str:\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    def make_request():\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000,\n",
    "                timeout=30\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Azure OpenAI request failed: {e}\")\n",
    "            raise\n",
    "    try:\n",
    "        config = RetryConfig(max_attempts=3, initial_delay=1.0)\n",
    "        return retry_with_backoff(make_request, config)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"All attempts failed: {e}\")\n",
    "        return f\"I'm experiencing technical difficulties right now. Please try again later. Error: {str(e)[:100]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061744ed",
   "metadata": {},
   "source": [
    "# 6. User Information Extraction with Fallbacks\n",
    "\n",
    "This function extracts user information with graceful degradation, partial data handling, and multiple fallback strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2f3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInfo(BaseModel):\n",
    "    name: Optional[str] = None\n",
    "    email: Optional[str] = None\n",
    "    age: Optional[int] = None\n",
    "    phone: Optional[str] = None\n",
    "    company: Optional[str] = None\n",
    "\n",
    "def extract_user_info_with_fallback(prompt: str) -> dict:\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    system_prompt = \"\"\"\n",
    "    Extract user information from the text and return as JSON.\n",
    "    {\"name\": \"string or null\", \"email\": \"string or null\", \"age\": \"number or null\", \"phone\": \"string or null\", \"company\": \"string or null\"}\n",
    "    Use null for missing fields.\n",
    "    \"\"\"\n",
    "    def extract_attempt():\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=500,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        response_text = response.choices[0].message.content\n",
    "        json_data = json.loads(response_text)\n",
    "        return UserInfo(**json_data)\n",
    "    try:\n",
    "        user_data = retry_with_backoff(\n",
    "            extract_attempt,\n",
    "            RetryConfig(max_attempts=2),\n",
    "            (json.JSONDecodeError, ValidationError, Exception)\n",
    "        )\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": user_data.model_dump(),\n",
    "            \"source\": \"structured_extraction\"\n",
    "        }\n",
    "    except ValidationError as e:\n",
    "        logger.warning(f\"Validation failed, attempting partial extraction: {e}\")\n",
    "        try:\n",
    "            simple_prompt = f\"Extract any available information from this text as JSON: {prompt}\\nUse this format: {{'name': 'string or null', 'email': 'string or null'}}\"\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": simple_prompt}],\n",
    "                temperature=0.0,\n",
    "                max_tokens=300,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            partial_data = json.loads(response.choices[0].message.content)\n",
    "            user_info = UserInfo(\n",
    "                name=partial_data.get(\"name\"),\n",
    "                email=partial_data.get(\"email\")\n",
    "            )\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"data\": user_info.model_dump(),\n",
    "                \"source\": \"partial_extraction\",\n",
    "                \"warning\": \"Some fields could not be extracted\"\n",
    "            }\n",
    "        except Exception as fallback_error:\n",
    "            logger.error(f\"Fallback extraction also failed: {fallback_error}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"data\": {\"name\": None, \"email\": None, \"age\": None, \"phone\": None, \"company\": None},\n",
    "            \"source\": \"fallback\",\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Complete extraction failure: {e}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"data\": {\"name\": None, \"email\": None, \"age\": None, \"phone\": None, \"company\": None},\n",
    "            \"source\": \"error_fallback\",\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2663113",
   "metadata": {},
   "source": [
    "# 7. Circuit Breaker Pattern Implementation\n",
    "\n",
    "This agent implements a circuit breaker to prevent cascading failures and monitor service health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b13e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResilientAgent:\n",
    "    \"\"\"\n",
    "    Agent with comprehensive resilience patterns and error recovery.\n",
    "    \"\"\"\n",
    "    def __init__(self, retry_config: RetryConfig = None):\n",
    "        self.client = get_azure_openai_client()\n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "        self.retry_config = retry_config or RetryConfig()\n",
    "        self.error_count = 0\n",
    "        self.success_count = 0\n",
    "        self.circuit_breaker_threshold = 5  # Open circuit after 5 consecutive failures\n",
    "        self.circuit_open = False\n",
    "        self.last_success_time = time.time()\n",
    "    def _should_circuit_break(self) -> bool:\n",
    "        if self.error_count >= self.circuit_breaker_threshold:\n",
    "            if time.time() - self.last_success_time > 300:\n",
    "                return True\n",
    "        return False\n",
    "    def _reset_circuit(self):\n",
    "        self.circuit_open = False\n",
    "        self.error_count = 0\n",
    "        self.last_success_time = time.time()\n",
    "    def safe_chat(self, prompt: str, fallback_response: str = None) -> dict:\n",
    "        if self.circuit_open or self._should_circuit_break():\n",
    "            self.circuit_open = True\n",
    "            fallback = fallback_response or \"Service temporarily unavailable. Please try again later.\"\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"response\": fallback,\n",
    "                \"source\": \"circuit_breaker\",\n",
    "                \"error\": \"Circuit breaker open\"\n",
    "            }\n",
    "        def make_chat_request():\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000,\n",
    "                timeout=30\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        try:\n",
    "            response = retry_with_backoff(make_chat_request, self.retry_config)\n",
    "            self.success_count += 1\n",
    "            self._reset_circuit()\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"response\": response,\n",
    "                \"source\": \"azure_openai\",\n",
    "                \"attempts\": \"multiple\" if self.retry_config.max_attempts > 1 else \"single\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.error_count += 1\n",
    "            logger.error(f\"Chat request failed after retries: {e}\")\n",
    "            fallback = fallback_response or f\"I'm having technical difficulties. Please try again. Error: {str(e)[:50]}\"\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"response\": fallback,\n",
    "                \"source\": \"error_fallback\",\n",
    "                \"error\": str(e),\n",
    "                \"error_count\": self.error_count\n",
    "            }\n",
    "    def get_health_status(self) -> dict:\n",
    "        return {\n",
    "            \"circuit_open\": self.circuit_open,\n",
    "            \"error_count\": self.error_count,\n",
    "            \"success_count\": self.success_count,\n",
    "            \"last_success_time\": self.last_success_time,\n",
    "            \"health\": \"healthy\" if not self.circuit_open and self.error_count < 3 else \"degraded\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc41ed",
   "metadata": {},
   "source": [
    "# 8. Comprehensive Testing Scenarios\n",
    "\n",
    "Let's test the control and recovery components with various scenarios, including normal operations and error conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426ef5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ControlAgent Demo ===\n",
      "\n",
      "1. Input: 'Hello there!'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:57:57,788 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:00,140 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:00,140 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 1 validation error for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Customer Service', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "   Intent: greeting (confidence: 0.99)\n",
      "   Reasoning: The user is initiating the conversation with a friendly salutation, which is a typical greeting.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: Hello! How can I assist you today? I can help with questions, requests, or connect you with the righ...\n",
      "\n",
      "2. Input: 'What is machine learning and how does it work?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:01,485 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:02,667 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:02,667 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 1 validation error for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Technical Support - AI/ML', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:07,843 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Intent: question (confidence: 0.98)\n",
      "   Reasoning: The user is asking for an explanation of what machine learning is and how it functions, which is a clear request for information.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: **Machine learning** is a branch of artificial intelligence (AI) that focuses on creating systems th...\n",
      "\n",
      "3. Input: 'Please schedule a meeting for tomorrow at 2 PM'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:11,508 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:12,593 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:12,593 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 2 validation errors for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Administration', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "priority\n",
      "  Input should be 'low', 'medium', 'high' or 'urgent' [type=literal_error, input_value='normal', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "   Intent: request (confidence: 0.98)\n",
      "   Reasoning: The user is asking for an action to be performed, specifically to schedule a meeting at a specified time. This is a clear request rather than a question, complaint, greeting, or goodbye.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: I've routed your request to our general team (Priority: medium). Expected response time: 30 minutes....\n",
      "\n",
      "4. Input: 'I'm unhappy with the service quality, my account is not working'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:14,040 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:15,088 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:15,088 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 2 validation errors for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Customer Support', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "priority\n",
      "  Input should be 'low', 'medium', 'high' or 'urgent' [type=literal_error, input_value='High', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "   Intent: complaint (confidence: 0.98)\n",
      "   Reasoning: The user expresses dissatisfaction with the service quality and mentions an issue with their account not working, which are clear indicators of a complaint.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: I understand your concern and I'm sorry you're experiencing this issue. I've escalated this to our g...\n",
      "\n",
      "5. Input: 'Thanks for your help, goodbye!'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:16,445 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:17,579 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:17,579 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 1 validation error for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Customer Service', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "   Intent: goodbye (confidence: 0.98)\n",
      "   Reasoning: The user is expressing gratitude and explicitly saying 'goodbye', which is a clear indicator of ending the conversation.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: Thank you for contacting us! Have a great day and feel free to reach out if you need anything else.\n",
      "\n",
      "6. Input: 'My API integration is failing with error 500'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:18,941 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:19,972 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:19,972 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 2 validation errors for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Technical Support', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "priority\n",
      "  Input should be 'low', 'medium', 'high' or 'urgent' [type=literal_error, input_value='High', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "   Intent: complaint (confidence: 0.95)\n",
      "   Reasoning: The user is reporting a problem with their API integration, specifically mentioning an error (500), which indicates dissatisfaction or an issue encountered.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: I understand your concern and I'm sorry you're experiencing this issue. I've escalated this to our g...\n",
      "\n",
      "7. Input: 'How much does your premium plan cost?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:21,381 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:22,447 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:22,447 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 2 validation errors for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Sales', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "priority\n",
      "  Input should be 'low', 'medium', 'high' or 'urgent' [type=literal_error, input_value='normal', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:24,477 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Intent: question (confidence: 0.98)\n",
      "   Reasoning: The user is asking for the price of the premium plan, which is a request for information and fits the definition of a question.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: I don’t sell services or have pricing plans myself. If you’re asking about the premium plan for Chat...\n",
      "\n",
      "8. Input: 'I can't log into my account and need help immediately'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:26,489 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:28,437 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:28,437 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 2 validation errors for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Technical Support', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "priority\n",
      "  Input should be 'low', 'medium', 'high' or 'urgent' [type=literal_error, input_value='High', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "   Intent: complaint (confidence: 0.95)\n",
      "   Reasoning: The user expresses frustration about being unable to log in and requests urgent assistance, which indicates a complaint about a problem they are experiencing.\n",
      "   Department: general, Priority: medium\n",
      "   Requires Human: True\n",
      "   Response: I understand your concern and I'm sorry you're experiencing this issue. I've escalated this to our g...\n",
      "\n",
      "=== Testing ControlAgent Conversation ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:29,760 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:30,799 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:30,799 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 2 validation errors for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Customer Support', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "priority\n",
      "  Input should be 'low', 'medium', 'high' or 'urgent' [type=literal_error, input_value='High', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "User: Hi, I need help with my account\n",
      "Agent: I've routed your request to our general team (Priority: medium). Expected response time: 30 minutes....\n",
      "Classification: request\n",
      "Routing: general (medium)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:32,185 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:33,157 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:33,157 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 1 validation error for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='IT Support', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "User: I can't access my dashboard and it's urgent\n",
      "Agent: I understand your concern and I'm sorry you're experiencing this issue. I've escalated this to our g...\n",
      "Classification: complaint\n",
      "Routing: general (medium)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:35,269 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:36,535 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:36,535 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing error: 1 validation error for RoutingDecision\n",
      "department\n",
      "  Input should be 'sales', 'support', 'billing', 'technical' or 'general' [type=literal_error, input_value='Customer Service', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/literal_error\n",
      "User: Thank you for your help\n",
      "Agent: Thank you for contacting us! Have a great day and feel free to reach out if you need anything else.\n",
      "Classification: goodbye\n",
      "Routing: general (medium)\n",
      "\n",
      "Conversation summary: 3 turns, Intents: ['request', 'complaint', 'goodbye'], Departments involved: ['general']\n",
      "\n",
      "=== Recovery: Resilient Intelligence ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:37,525 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Machine learning is a branch of artificial intelligence that enables computers to learn patterns fro...\n",
      "\n",
      "=== Recovery: User Info Extraction with Fallback ===\n",
      "   Test 1: 'My name is John Smith and my email is john@example.com'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:38,577 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Result: {'success': True, 'data': {'name': 'John Smith', 'email': 'john@example.com', 'age': None, 'phone': None, 'company': None}, 'source': 'structured_extraction'}\n",
      "\n",
      "   Test 2: 'Hi, I'm Jane'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:39,499 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Result: {'success': True, 'data': {'name': 'Jane', 'email': None, 'age': None, 'phone': None, 'company': None}, 'source': 'structured_extraction'}\n",
      "\n",
      "   Test 3: 'Contact me at invalid-email-format'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:40,504 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Result: {'success': True, 'data': {'name': None, 'email': None, 'age': None, 'phone': None, 'company': None}, 'source': 'structured_extraction'}\n",
      "\n",
      "\n",
      "=== Recovery: Resilient Agent with Circuit Breaker ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:41,404 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat 1: {'success': True, 'response': '2 + 2 = **4**', 'source': 'azure_openai', 'attempts': 'multiple'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:48,566 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-07-29 10:58:48,712 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/invalid-deployment-name/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 404 DeploymentNotFound\"\n",
      "2025-07-29 10:58:48,713 - WARNING - Attempt 1 failed: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}. Retrying in 0.44 seconds...\n",
      "2025-07-29 10:58:48,712 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/invalid-deployment-name/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 404 DeploymentNotFound\"\n",
      "2025-07-29 10:58:48,713 - WARNING - Attempt 1 failed: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}. Retrying in 0.44 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat 2: {'success': True, 'response': \"Absolutely! Here’s a clear explanation of **quantum computing**:\\n\\n---\\n\\n### What is Quantum Computing?\\n\\n**Quantum computing** is a branch of computing that uses the principles of quantum mechanics—the science that explains how things work at the smallest scales, like atoms and subatomic particles—to process information in entirely new ways.\\n\\n#### Classical vs. Quantum Computers\\n\\n- **Classical Computers:**  \\n  The computers we use every day store and process information as **bits**, which can be either 0 or 1.\\n- **Quantum Computers:**  \\n  These use **quantum bits** or **qubits**, which can be 0, 1, or **both at the same time** (thanks to a property called **superposition**).\\n\\n---\\n\\n### Key Quantum Concepts\\n\\n1. **Superposition:**  \\n   A qubit can be in a state of 0, 1, or any combination of both at once. This allows quantum computers to process many possibilities simultaneously.\\n\\n2. **Entanglement:**  \\n   Qubits can be linked together so that the state of one instantly affects the state of another, even if they're far apart. This lets quantum computers solve certain problems much faster than classical computers.\\n\\n3. **Interference:**  \\n   Quantum computers use interference to amplify correct answers and cancel out wrong ones in calculations.\\n\\n---\\n\\n### Why is Quantum Computing Important?\\n\\nQuantum computers can theoretically solve some problems much faster than classical computers. For example:\\n\\n- **Breaking certain cryptographic codes**\\n- **Modeling complex molecules for drug discovery**\\n- **Optimizing large systems (e.g., supply chains, traffic flows)**\\n\\n---\\n\\n### Are Quantum Computers Ready Now?\\n\\nQuantum computers are still in the early stages. Building and controlling qubits is very challenging, and today's quantum computers are mostly used for research. But their potential is enormous.\\n\\n---\\n\\n### In Summary\\n\\n**Quantum computing** harnesses strange quantum phenomena to process information in fundamentally new ways, with the potential to revolutionize fields like cryptography, chemistry, and optimization.\\n\\nIf you want a deeper dive or an analogy, just ask!\", 'source': 'azure_openai', 'attempts': 'multiple'}\n",
      "Agent health: {'circuit_open': False, 'error_count': 0, 'success_count': 2, 'last_success_time': 1753801128.5691452, 'health': 'healthy'}\n",
      "\n",
      "Testing error scenario...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:58:49,298 - INFO - HTTP Request: POST https://aq-ai-foundry-sweden-central.openai.azure.com/openai/deployments/invalid-deployment-name/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 404 DeploymentNotFound\"\n",
      "2025-07-29 10:58:49,299 - ERROR - All 2 attempts failed. Last error: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\n",
      "2025-07-29 10:58:49,300 - ERROR - Chat request failed after retries: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error test result: {'success': False, 'response': \"I'm having technical difficulties. Please try again. Error: Error code: 404 - {'error': {'code': 'DeploymentNo\", 'source': 'error_fallback', 'error': \"Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}\", 'error_count': 1}\n",
      "Final health status: {'circuit_open': False, 'error_count': 1, 'success_count': 2, 'last_success_time': 1753801128.5691452, 'health': 'healthy'}\n"
     ]
    }
   ],
   "source": [
    "# Test ControlAgent with different types of inputs\n",
    "print(\"=== ControlAgent Demo ===\\n\")\n",
    "test_inputs = [\n",
    "    \"Hello there!\",\n",
    "    \"What is machine learning and how does it work?\",\n",
    "    \"Please schedule a meeting for tomorrow at 2 PM\",\n",
    "    \"I'm unhappy with the service quality, my account is not working\",\n",
    "    \"Thanks for your help, goodbye!\",\n",
    "    \"My API integration is failing with error 500\",\n",
    "    \"How much does your premium plan cost?\",\n",
    "    \"I can't log into my account and need help immediately\"\n",
    "]\n",
    "for i, user_input in enumerate(test_inputs, 1):\n",
    "    print(f\"{i}. Input: '{user_input}'\")\n",
    "    try:\n",
    "        result, classification, routing = route_based_on_intent(user_input)\n",
    "        print(f\"   Intent: {classification.intent} (confidence: {classification.confidence:.2f})\")\n",
    "        print(f\"   Reasoning: {classification.reasoning}\")\n",
    "        print(f\"   Department: {routing.department}, Priority: {routing.priority}\")\n",
    "        print(f\"   Requires Human: {routing.requires_human}\")\n",
    "        print(f\"   Response: {result[:100]}{'...' if len(result) > 100 else ''}\")\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(f\"   Error: {e}\")\n",
    "        print()\n",
    "\n",
    "# Test the ControlAgent conversation\n",
    "print(\"=== Testing ControlAgent Conversation ===\\n\")\n",
    "agent = ControlAgent()\n",
    "test_conversation = [\n",
    "    \"Hi, I need help with my account\",\n",
    "    \"I can't access my dashboard and it's urgent\",\n",
    "    \"Thank you for your help\"\n",
    "]\n",
    "for msg in test_conversation:\n",
    "    result = agent.process_input(msg)\n",
    "    print(f\"User: {msg}\")\n",
    "    print(f\"Agent: {result['response'][:100]}{'...' if len(result['response']) > 100 else ''}\")\n",
    "    print(f\"Classification: {result['classification']['intent']}\")\n",
    "    print(f\"Routing: {result['routing']['department']} ({result['routing']['priority']})\")\n",
    "    print()\n",
    "print(agent.get_conversation_summary())\n",
    "\n",
    "# Test Recovery: Resilient Intelligence\n",
    "print(\"\\n=== Recovery: Resilient Intelligence ===\")\n",
    "try:\n",
    "    result = resilient_intelligence(\"Tell me about machine learning in one sentence\")\n",
    "    print(f\"Success: {result[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")\n",
    "\n",
    "# Test Recovery: User info extraction with fallback\n",
    "print(\"\\n=== Recovery: User Info Extraction with Fallback ===\")\n",
    "test_prompts = [\n",
    "    \"My name is John Smith and my email is john@example.com\",\n",
    "    \"Hi, I'm Jane\",\n",
    "    \"Contact me at invalid-email-format\",\n",
    "]\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"   Test {i}: '{prompt}'\")\n",
    "    result = extract_user_info_with_fallback(prompt)\n",
    "    print(f\"   Result: {result}\")\n",
    "    print()\n",
    "\n",
    "# Test Recovery: Resilient agent with circuit breaker\n",
    "print(\"\\n=== Recovery: Resilient Agent with Circuit Breaker ===\")\n",
    "agent = ResilientAgent(RetryConfig(max_attempts=2, initial_delay=0.5))\n",
    "result1 = agent.safe_chat(\"What is 2+2?\")\n",
    "print(f\"Chat 1: {result1}\")\n",
    "result2 = agent.safe_chat(\n",
    "    \"Explain quantum computing\", \n",
    "    fallback_response=\"Quantum computing is complex. Please consult our documentation.\"\n",
    ")\n",
    "print(f\"Chat 2: {result2}\")\n",
    "health = agent.get_health_status()\n",
    "print(f\"Agent health: {health}\")\n",
    "# Simulate error scenario\n",
    "print(f\"\\nTesting error scenario...\")\n",
    "original_deployment = agent.deployment_name\n",
    "agent.deployment_name = \"invalid-deployment-name\"\n",
    "result3 = agent.safe_chat(\"This should fail gracefully\")\n",
    "print(f\"Error test result: {result3}\")\n",
    "agent.deployment_name = original_deployment\n",
    "final_health = agent.get_health_status()\n",
    "print(f\"Final health status: {final_health}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078d18c",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook, we've implemented advanced control and recovery building blocks for Azure OpenAI agents:\n",
    "- **Control**: Intent classification, request routing, and decision tree orchestration\n",
    "- **Recovery**: Retry logic, exponential backoff, error handling, circuit breaker, and resilience patterns\n",
    "\n",
    "These patterns enable robust, production-ready AI agents that can manage complex workflows and recover gracefully from failures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
