{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385c2a82",
   "metadata": {},
   "source": [
    "# 7: Feedback - Human-in-the-Loop and Approval Workflows for Azure OpenAI Agents\n",
    "\n",
    "This notebook demonstrates how to implement feedback and approval workflows in Azure OpenAI agents, including:\n",
    "- Human-in-the-loop approval for high-risk or sensitive content\n",
    "- Risk assessment using Azure OpenAI\n",
    "- Approval request and decision schemas\n",
    "- Batch approval and workflow management\n",
    "\n",
    "These patterns are essential for responsible AI, compliance, and production-grade deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b970ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install openai azure-identity python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57cc096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional, Dict, List, Callable\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8c047",
   "metadata": {},
   "source": [
    "## Azure OpenAI Client Initialization\n",
    "This function initializes the Azure OpenAI client using either API key or Managed Identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6606b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_openai_client():\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    if api_key:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    else:\n",
    "        credential = DefaultAzureCredential()\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=credential,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff610e3f",
   "metadata": {},
   "source": [
    "## Approval Request and Decision Schemas\n",
    "We use Pydantic models to define the structure for approval requests and decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c6ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApprovalRequest(BaseModel):\n",
    "    id: str = Field(description=\"Unique identifier for the request\")\n",
    "    content: str = Field(description=\"Content to be reviewed\")\n",
    "    type: str = Field(description=\"Type of content (email, document, response, etc.)\")\n",
    "    risk_level: str = Field(description=\"Risk level: low, medium, high, critical\")\n",
    "    requester: str = Field(description=\"Who requested the approval\")\n",
    "    timestamp: str = Field(description=\"When the request was created\")\n",
    "    context: Optional[str] = Field(None, description=\"Additional context for the approval\")\n",
    "\n",
    "class ApprovalDecision(BaseModel):\n",
    "    approved: bool = Field(description=\"Whether the content was approved\")\n",
    "    feedback: Optional[str] = Field(None, description=\"Human feedback or comments\")\n",
    "    modifications: Optional[str] = Field(None, description=\"Suggested modifications\")\n",
    "    approver: str = Field(description=\"Who made the approval decision\")\n",
    "    timestamp: str = Field(description=\"When the decision was made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb42ee",
   "metadata": {},
   "source": [
    "## Risk Assessment with Azure OpenAI\n",
    "This function uses Azure OpenAI to assess the risk level of content for public or customer communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3fa7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_content_risk(content: str) -> str:\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    risk_assessment_prompt = f\"\"\"\n",
    "Assess the risk level of this content for public or customer communication:\n",
    "\n",
    "Content: \"{content}\"\n",
    "\n",
    "Consider:\n",
    "- Potential for misunderstanding\n",
    "- Legal or compliance issues\n",
    "- Brand reputation impact\n",
    "- Sensitive information disclosure\n",
    "- Emotional or controversial topics\n",
    "\n",
    "Return only one word: low, medium, high, or critical\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": risk_assessment_prompt}],\n",
    "            temperature=0.1,\n",
    "            max_tokens=50,\n",
    "        )\n",
    "        risk_level = response.choices[0].message.content.strip().lower()\n",
    "        if risk_level in [\"low\", \"medium\", \"high\", \"critical\"]:\n",
    "            return risk_level\n",
    "        else:\n",
    "            return \"medium\"  # Default fallback\n",
    "    except Exception as e:\n",
    "        print(f\"Risk assessment failed: {e}\")\n",
    "        return \"high\"  # Conservative default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb86fb",
   "metadata": {},
   "source": [
    "## Human Approval Workflow\n",
    "This function provides a simple human-in-the-loop approval interface for content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf6686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_approval(content: str, content_type: str = \"general\") -> bool:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"APPROVAL REQUEST - {content_type.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Content to review:\\n{content}\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    while True:\n",
    "        response = input(\"Approve this content? (y)es / (n)o / (m)odify / (v)iew again: \").lower().strip()\n",
    "        if response.startswith('y'):\n",
    "            return True\n",
    "        elif response.startswith('n'):\n",
    "            return False\n",
    "        elif response.startswith('m'):\n",
    "            modification = input(\"What modifications would you suggest? \")\n",
    "            print(f\"Modifications noted: {modification}\")\n",
    "            return False\n",
    "        elif response.startswith('v'):\n",
    "            print(f\"\\nContent:\\n{content}\\n\")\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Please enter 'y' for yes, 'n' for no, 'm' for modify, or 'v' to view again.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c76d89",
   "metadata": {},
   "source": [
    "## Content Generation with Human Feedback\n",
    "This function generates content with Azure OpenAI and optionally requires human approval based on risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdcf97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intelligence_with_human_feedback(prompt: str, require_approval: bool = True) -> dict:\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        draft_content = response.choices[0].message.content\n",
    "        result = {\"content\": draft_content, \"generated_at\": datetime.now().isoformat(), \"prompt\": prompt}\n",
    "        if require_approval:\n",
    "            risk_level = assess_content_risk(draft_content)\n",
    "            result[\"risk_level\"] = risk_level\n",
    "            needs_approval = risk_level in [\"high\", \"critical\"]\n",
    "            if needs_approval:\n",
    "                approved = get_human_approval(draft_content, \"AI Generated Content\")\n",
    "                result[\"approved\"] = approved\n",
    "                result[\"approval_required\"] = True\n",
    "                result[\"status\"] = \"approved\" if approved else \"rejected\"\n",
    "            else:\n",
    "                result[\"approved\"] = True\n",
    "                result[\"approval_required\"] = False\n",
    "                result[\"status\"] = f\"auto_approved (risk level: {risk_level})\"\n",
    "        else:\n",
    "            result[\"approved\"] = True\n",
    "            result[\"approval_required\"] = False\n",
    "            result[\"status\"] = \"no_approval_needed\"\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"status\": \"error\", \"approved\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d636a",
   "metadata": {},
   "source": [
    "## Approval Workflow Manager\n",
    "This class manages approval requests, processes approvals, and tracks statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf3e0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApprovalWorkflow:\n",
    "    def __init__(self):\n",
    "        self.client = get_azure_openai_client()\n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "        self.pending_approvals: List[ApprovalRequest] = []\n",
    "        self.approval_history: List[Dict] = []\n",
    "    def submit_for_approval(self, content: str, content_type: str = 'general', requester: str = 'system', context: Optional[str] = None) -> str:\n",
    "        risk_level = assess_content_risk(content)\n",
    "        request_id = f'req_{len(self.pending_approvals) + 1}_{datetime.now().strftime('%Y%m%d_%H%M%S')}'\n",
    "        approval_request = ApprovalRequest(\n",
    "            id=request_id,\n",
    "            content=content,\n",
    "            type=content_type,\n",
    "            risk_level=risk_level,\n",
    "            requester=requester,\n",
    "            timestamp=datetime.now().isoformat(),\n",
    "            context=context\n",
    "        )\n",
    "        self.pending_approvals.append(approval_request)\n",
    "        print(f'📋 Approval request {request_id} submitted (Risk: {risk_level})')\n",
    "        return request_id\n",
    "    def process_approval(self, request_id: str, approver: str = 'human') -> Optional[ApprovalDecision]:\n",
    "        request = next((req for req in self.pending_approvals if req.id == request_id), None)\n",
    "        if not request:\n",
    "            print(f'❌ Approval request {request_id} not found')\n",
    "            return None\n",
    "        print(f'📋 Processing approval request: {request_id}')\n",
    "        print(f'Type: {request.type}')\n",
    "        print(f'Risk Level: {request.risk_level}')\n",
    "        print(f'Requester: {request.requester}')\n",
    "        if request.context:\n",
    "            print(f'Context: {request.context}')\n",
    "        print(f'Submitted: {request.timestamp}')\n",
    "        approved = get_human_approval(request.content, request.type)\n",
    "        feedback = None\n",
    "        modifications = None\n",
    "        if not approved:\n",
    "            feedback = input('Please provide feedback (optional): ').strip()\n",
    "            modifications = input('Suggest modifications (optional): ').strip()\n",
    "        decision = ApprovalDecision(\n",
    "            approved=approved,\n",
    "            feedback=feedback if feedback else None,\n",
    "            modifications=modifications if modifications else None,\n",
    "            approver=approver,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "        self.approval_history.append({\"request\": request.model_dump(), \"decision\": decision.model_dump()})\n",
    "        self.pending_approvals.remove(request)\n",
    "        return decision\n",
    "    def process_all_pending(self, approver: str = 'human') -> List[ApprovalDecision]:\n",
    "        decisions = []\n",
    "        while self.pending_approvals:\n",
    "            request = self.pending_approvals[0]\n",
    "            decision = self.process_approval(request.id, approver)\n",
    "            if decision:\n",
    "                decisions.append(decision)\n",
    "        return decisions\n",
    "    def get_pending_count(self) -> int:\n",
    "        return len(self.pending_approvals)\n",
    "    def get_approval_stats(self) -> Dict:\n",
    "        if not self.approval_history:\n",
    "            return {\"total\": 0, \"approved\": 0, \"rejected\": 0, \"approval_rate\": 0.0}\n",
    "        total = len(self.approval_history)\n",
    "        approved = sum(1 for item in self.approval_history if item[\"decision\"][\"approved\"])\n",
    "        rejected = total - approved\n",
    "        approval_rate = approved / total if total > 0 else 0.0\n",
    "        return {\"total\": total, \"approved\": approved, \"rejected\": rejected, \"approval_rate\": approval_rate}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f91b53",
   "metadata": {},
   "source": [
    "## Example: Content Generation and Approval\n",
    "Let's generate content and walk it through the approval workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0779f37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'content': 'A hum of circuits, silent light,  \\nWires weaving through the night.  \\nIdeas dance on glass and code,  \\nWorlds connected, stories told.\\n\\nBright screens shimmer, casting dreams,  \\nBoundless knowledge flows in streams.  \\nYet in the glow, let’s not forget  \\nThe human heart, our greatest tech.', 'generated_at': '2025-07-29T11:11:22.986711', 'prompt': 'Write a short poem about technology', 'risk_level': 'low', 'approved': True, 'approval_required': False, 'status': 'auto_approved (risk level: low)'}\n"
     ]
    }
   ],
   "source": [
    "# Generate content and require approval\n",
    "result = intelligence_with_human_feedback(\"Write a short poem about technology\")\n",
    "print(f'Result: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e09497",
   "metadata": {},
   "source": [
    "## Example: Approval Workflow Manager\n",
    "Let's submit multiple items for approval and process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98d6945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Approval request req_1_20250729_111144 submitted (Risk: low)\n",
      "📋 Approval request req_2_20250729_111145 submitted (Risk: medium)\n",
      "Pending approvals: 2\n",
      "📋 Processing approval request: req_1_20250729_111144\n",
      "Type: customer_email\n",
      "Risk Level: low\n",
      "Requester: customer_service\n",
      "Submitted: 2025-07-29T11:11:44.274928\n",
      "============================================================\n",
      "APPROVAL REQUEST - CUSTOMER_EMAIL\n",
      "============================================================\n",
      "Content to review:\n",
      "Thank you for your purchase! Your order will arrive in 2-3 business days.\n",
      "\n",
      "============================================================\n",
      "Decision: {\n",
      "  \"approved\": true,\n",
      "  \"feedback\": null,\n",
      "  \"modifications\": null,\n",
      "  \"approver\": \"human\",\n",
      "  \"timestamp\": \"2025-07-29T11:11:51.421310\"\n",
      "}\n",
      "Approval stats: {'total': 1, 'approved': 1, 'rejected': 0, 'approval_rate': 1.0}\n"
     ]
    }
   ],
   "source": [
    "workflow = ApprovalWorkflow()\n",
    "req1 = workflow.submit_for_approval(\"Thank you for your purchase! Your order will arrive in 2-3 business days.\", 'customer_email', 'customer_service')\n",
    "req2 = workflow.submit_for_approval(\"We're sorry to inform you that your account has been temporarily suspended due to suspicious activity.\", 'account_notification', 'security_team', 'Automated fraud detection triggered')\n",
    "print(f'Pending approvals: {workflow.get_pending_count()}')\n",
    "decision1 = workflow.process_approval(req1)\n",
    "print(f'Decision: {decision1.model_dump_json(indent=2) if decision1 else 'None'}')\n",
    "stats = workflow.get_approval_stats()\n",
    "print(f'Approval stats: {stats}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a787c78",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this notebook, we've implemented feedback and approval workflows for Azure OpenAI agents, including human-in-the-loop, risk assessment, and batch approval management."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
