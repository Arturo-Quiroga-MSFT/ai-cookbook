{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0be625",
   "metadata": {},
   "source": [
    "## Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5f62f",
   "metadata": {},
   "source": [
    "\n",
    "Intelligence: The \"brain\" that processes information and makes decisions using Azure OpenAI LLMs.\n",
    "This component handles context understanding, instruction following, and response generation.\n",
    "\n",
    "Azure OpenAI Documentation: https://docs.microsoft.com/en-us/azure/cognitive-services/openai/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa620a",
   "metadata": {},
   "source": [
    "### Load required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ef03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3a26d",
   "metadata": {},
   "source": [
    "### Initialize Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f489aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_openai_client():\n",
    "    \"\"\"\n",
    "    Initialize Azure OpenAI client with proper authentication.\n",
    "    \n",
    "    Uses API key authentication for development and Managed Identity for production.\n",
    "    \"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    \n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    # Use API key if available (development), otherwise use Managed Identity (production)\n",
    "    if api_key:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    else:\n",
    "        # Use Managed Identity for production environments\n",
    "        credential = DefaultAzureCredential()\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=credential,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    \n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b1166",
   "metadata": {},
   "source": [
    "### Basic Intelligence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee1f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Intelligence Output:\n",
      "**Artificial intelligence (AI)** is a branch of computer science focused on creating systems or machines that can perform tasks that typically require human intelligence. These tasks include:\n",
      "\n",
      "- **Learning** (acquiring knowledge and skills, adapting to new situations)\n",
      "- **Reasoning** (solving problems and making decisions)\n",
      "- **Perception** (understanding images, sounds, and other sensory inputs)\n",
      "- **Language understanding** (processing and generating human language)\n",
      "\n",
      "AI can be found in applications like:\n",
      "\n",
      "- Virtual assistants (e.g., Siri, Alexa)\n",
      "- Recommendation systems (e.g., Netflix, Amazon)\n",
      "- Self-driving cars\n",
      "- Image and speech recognition\n",
      "\n",
      "In essence, **AI aims to simulate human-like intelligence in machines**, allowing them to perform complex tasks with minimal human intervention.\n"
     ]
    }
   ],
   "source": [
    "def basic_intelligence(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Basic intelligence function using Azure OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The input prompt for the AI model\n",
    "        \n",
    "    Returns:\n",
    "        Generated response text\n",
    "    \"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_DEPLOYMENT\", \"gpt-4o\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the basic intelligence function\n",
    "    result = basic_intelligence(prompt=\"What is artificial intelligence?\")\n",
    "    print(\"Basic Intelligence Output:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496020d",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24866b",
   "metadata": {},
   "source": [
    "\n",
    "Memory: Stores and retrieves relevant information across interactions with Azure OpenAI.\n",
    "This component maintains conversation history and context to enable coherent multi-turn interactions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e55148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_openai_client():\n",
    "    \"\"\"\n",
    "    Initialize Azure OpenAI client with proper authentication.\n",
    "    \n",
    "    Uses API key authentication for development and Managed Identity for production.\n",
    "    \"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "    \n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    # Use API key if available (development), otherwise use Managed Identity (production)\n",
    "    if api_key:\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    else:\n",
    "        # Use Managed Identity for production environments\n",
    "        credential = DefaultAzureCredential()\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=credential,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "    \n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c294d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_joke_without_memory():\n",
    "    \"\"\"Ask for a joke without maintaining conversation history.\"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Tell me a joke about programming\"},\n",
    "            ],\n",
    "            temperature=0.8,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\"\n",
    "\n",
    "def ask_followup_without_memory():\n",
    "    \"\"\"Ask a follow-up question without conversation context.\"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"What was my previous question?\"},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\"\n",
    "\n",
    "\n",
    "def ask_followup_with_memory(joke_response: str):\n",
    "    \"\"\"Ask a follow-up question with conversation history maintained.\"\"\"\n",
    "    client = get_azure_openai_client()\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    # Maintain conversation history by including previous messages\n",
    "    conversation_history = [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke about programming\"},\n",
    "        {\"role\": \"assistant\", \"content\": joke_response},\n",
    "        {\"role\": \"user\", \"content\": \"What was my previous question?\"},\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment_name,\n",
    "            messages=conversation_history,\n",
    "            temperature=0.7,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Azure OpenAI: {e}\")\n",
    "        return f\"Error: Unable to process request. {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8f13f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Memory Demo ===\n",
      "\n",
      "1. Asking for a joke...\n",
      "Response: Why do programmers prefer dark mode?  \n",
      "Because light attracts bugs!\n",
      "\n",
      "2. Asking follow-up without memory...\n",
      "Response: I'm sorry, but I don't have access to your previous question. How can I assist you today?\n",
      "\n",
      "3. Asking follow-up with memory...\n",
      "Response: Your previous question was: \"Tell me a joke about programming.\"\n",
      "\n",
      "4. Using ConversationMemory class...\n",
      "Response 1: Python is a high-level, interpreted programming language known for its simplicity, readability, and versatility. It was created by Guido van Rossum and first released in 1991. Python emphasizes code readability with its clean and easy-to-understand syntax, making it an excellent choice for beginners as well as experienced developers.\n",
      "\n",
      "### Key Features of Python:\n",
      "- **Easy to Learn and Use:** Python's syntax is straightforward and resembles natural language, which reduces the learning curve.\n",
      "- **Interpreted Language:** Python code is executed line-by-line, which makes debugging easier.\n",
      "- **Dynamically Typed:** You don’t need to declare variable types explicitly.\n",
      "- **Extensive Standard Library:** Comes with a large collection of modules and packages for various tasks such as file I/O, system calls, web development, and more.\n",
      "- **Cross-platform:** Runs on many operating systems including Windows, macOS, Linux, and more.\n",
      "- **Supports Multiple Programming Paradigms:** Including procedural, object-oriented, and functional programming.\n",
      "- **Large Community and Ecosystem:** Python has a vast ecosystem of third-party libraries and frameworks, like NumPy, pandas, Django, Flask, TensorFlow, and others.\n",
      "\n",
      "### Common Uses of Python:\n",
      "- **Web Development:** Frameworks like Django and Flask.\n",
      "- **Data Science and Machine Learning:** Libraries such as NumPy, pandas, scikit-learn, TensorFlow, and PyTorch.\n",
      "- **Automation and Scripting:** Writing scripts to automate repetitive tasks.\n",
      "- **Software Development:** Prototyping and building applications.\n",
      "- **Scientific Computing:** Tools for math, science, and engineering.\n",
      "- **Game Development:** Using libraries such as Pygame.\n",
      "\n",
      "### Example Python Code:\n",
      "```python\n",
      "# Simple program to print \"Hello, World!\"\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "Python’s versatility and ease of use continue to make it one of the most popular programming languages in the world. If you want to learn Python, there are many online tutorials, courses, and resources available to get started.\n",
      "\n",
      "Response 2: Python has several main advantages that contribute to its widespread popularity:\n",
      "\n",
      "1. **Easy to Learn and Use:**  \n",
      "   Python’s simple and clear syntax is designed to be readable and beginner-friendly, making it easier for new programmers to pick up and write code quickly.\n",
      "\n",
      "2. **Versatility:**  \n",
      "   Python supports multiple programming paradigms (procedural, object-oriented, functional) and is used in many domains such as web development, data science, artificial intelligence, automation, scientific computing, and more.\n",
      "\n",
      "3. **Large Standard Library and Ecosystem:**  \n",
      "   Python comes with a rich standard library that provides modules and functions for many common tasks, reducing the need to write code from scratch. Additionally, its extensive ecosystem of third-party libraries and frameworks (like NumPy, Django, Flask, TensorFlow) enables rapid development.\n",
      "\n",
      "4. **Cross-Platform Compatibility:**  \n",
      "   Python runs on almost all major operating systems (Windows, macOS, Linux), allowing developers to write code that can run anywhere with little or no modification.\n",
      "\n",
      "5. **Strong Community Support:**  \n",
      "   Python has a large, active community of developers who contribute to its libraries, provide tutorials, and offer support, making it easier to find help and resources.\n",
      "\n",
      "6. **Interpreted Language:**  \n",
      "   Python executes code line-by-line, which simplifies debugging and testing since you can run code interactively without compiling.\n",
      "\n",
      "7. **Integration Capabilities:**  \n",
      "   Python can easily integrate with other languages like C, C++, and Java, and can be embedded within applications to provide scripting capabilities.\n",
      "\n",
      "8. **Rapid Development:**  \n",
      "   The simplicity of Python’s syntax and the availability of powerful libraries help developers prototype and build applications quickly.\n",
      "\n",
      "These advantages collectively make Python a powerful and flexible language suitable for beginners and professionals alike.\n",
      "\n",
      "Response 3: Certainly! Here’s a simple example in Python that demonstrates basic concepts like variables, user input, conditional statements, and loops.\n",
      "\n",
      "### Example: A program that asks the user for their name and age, then tells them how many years until they turn 100.\n",
      "\n",
      "```python\n",
      "# Ask the user for their name\n",
      "name = input(\"What is your name? \")\n",
      "\n",
      "# Ask the user for their age and convert it to an integer\n",
      "age = int(input(\"How old are you? \"))\n",
      "\n",
      "# Calculate years left until 100\n",
      "years_left = 100 - age\n",
      "\n",
      "# Check if the user is already 100 or older\n",
      "if years_left > 0:\n",
      "    print(f\"Hello, {name}! You will turn 100 in {years_left} years.\")\n",
      "elif years_left == 0:\n",
      "    print(f\"Wow, {name}! You are 100 years old this year!\")\n",
      "else:\n",
      "    print(f\"Hello, {name}! You turned 100 {-years_left} years ago.\")\n",
      "\n",
      "# Optional: count down the last 5 years until 100 (if user is younger than 100)\n",
      "if years_left > 0 and years_left <= 5:\n",
      "    print(\"Counting down to 100:\")\n",
      "    for year in range(years_left, 0, -1):\n",
      "        print(year)\n",
      "```\n",
      "\n",
      "### How it works:\n",
      "- The program uses `input()` to get data from the user.\n",
      "- It converts the age input into an integer for calculation.\n",
      "- It uses `if-elif-else` statements to handle different age cases.\n",
      "- It uses a `for` loop to count down if the user is close to 100.\n",
      "\n",
      "You can run this code in any Python environment to see it in action!\n",
      "\n",
      "Total messages in conversation: 6\n"
     ]
    }
   ],
   "source": [
    "class ConversationMemory:\n",
    "    \"\"\"\n",
    "    A simple conversation memory class to manage chat history.\n",
    "    In production, you might want to store this in a database or Redis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "        self.client = get_azure_openai_client()\n",
    "        self.deployment_name = os.getenv(\"AZURE_OPENAI_GPT4_MINI_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "    \n",
    "    def add_user_message(self, content: str):\n",
    "        \"\"\"Add a user message to the conversation history.\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "    \n",
    "    def add_assistant_message(self, content: str):\n",
    "        \"\"\"Add an assistant message to the conversation history.\"\"\"\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "    \n",
    "    def get_response(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Get a response from Azure OpenAI while maintaining conversation context.\n",
    "        \n",
    "        Args:\n",
    "            user_input: The user's input message\n",
    "            \n",
    "        Returns:\n",
    "            Assistant's response\n",
    "        \"\"\"\n",
    "        # Add user message to history\n",
    "        self.add_user_message(user_input)\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment_name,\n",
    "                messages=self.messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=1000,\n",
    "            )\n",
    "            \n",
    "            assistant_response = response.choices[0].message.content\n",
    "            \n",
    "            # Add assistant response to history\n",
    "            self.add_assistant_message(assistant_response)\n",
    "            \n",
    "            return assistant_response\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: Unable to process request. {str(e)}\"\n",
    "            self.add_assistant_message(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        self.messages = []\n",
    "    \n",
    "    def get_message_count(self) -> int:\n",
    "        \"\"\"Get the number of messages in the conversation history.\"\"\"\n",
    "        return len(self.messages)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Memory Demo ===\\n\")\n",
    "    \n",
    "    # First: Ask for a joke without memory\n",
    "    print(\"1. Asking for a joke...\")\n",
    "    joke_response = ask_joke_without_memory()\n",
    "    print(f\"Response: {joke_response}\\n\")\n",
    "\n",
    "    # Second: Ask follow-up without memory (AI will be confused)\n",
    "    print(\"2. Asking follow-up without memory...\")\n",
    "    confused_response = ask_followup_without_memory()\n",
    "    print(f\"Response: {confused_response}\\n\")\n",
    "\n",
    "    # Third: Ask follow-up with memory (AI will remember)\n",
    "    print(\"3. Asking follow-up with memory...\")\n",
    "    memory_response = ask_followup_with_memory(joke_response)\n",
    "    print(f\"Response: {memory_response}\\n\")\n",
    "    \n",
    "    # Fourth: Demonstrate conversation memory class\n",
    "    print(\"4. Using ConversationMemory class...\")\n",
    "    conversation = ConversationMemory()\n",
    "    \n",
    "    # Have a multi-turn conversation\n",
    "    response1 = conversation.get_response(\"Tell me about Python programming\")\n",
    "    print(f\"Response 1: {response1}\\n\")\n",
    "    \n",
    "    response2 = conversation.get_response(\"What are its main advantages?\")\n",
    "    print(f\"Response 2: {response2}\\n\")\n",
    "    \n",
    "    response3 = conversation.get_response(\"Can you give me a simple example?\")\n",
    "    print(f\"Response 3: {response3}\\n\")\n",
    "    \n",
    "    print(f\"Total messages in conversation: {conversation.get_message_count()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
